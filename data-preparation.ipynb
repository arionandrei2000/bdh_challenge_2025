{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "240cfd52",
      "metadata": {
        "id": "240cfd52"
      },
      "source": [
        "# This notebook prepares data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ta\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import kagglehub\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from ta.trend import MACD\n",
        "from ta.volatility import BollingerBands, AverageTrueRange\n",
        "from ta.momentum import RSIIndicator\n",
        "\n",
        "# 1) Set up Google Drive project\n",
        "\n",
        "PROJECT_DIR = \"/content/drive/MyDrive/bitcoin_project\"\n",
        "os.makedirs(PROJECT_DIR, exist_ok=True)\n",
        "print(\"Project folder created:\", PROJECT_DIR)\n",
        "\n",
        "folders = [\n",
        "    \"raw\",\n",
        "    \"cleaned\",\n",
        "    \"filtered\",\n",
        "    \"splits\",\n",
        "    \"features\",\n",
        "    \"windows\",\n",
        "    \"normalized\",\n",
        "    \"models\",\n",
        "    \"results\",\n",
        "]\n",
        "\n",
        "for f in folders:\n",
        "    os.makedirs(f\"{PROJECT_DIR}/{f}\", exist_ok=True)\n",
        "\n",
        "print(\"All project folders created!\")"
      ],
      "metadata": {
        "id": "JYMypMq3adp-",
        "outputId": "3df28815-ea0d-4d2a-8b6d-dc1892b997aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "JYMypMq3adp-",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ta in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from ta) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from ta) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->ta) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->ta) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->ta) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->ta) (1.17.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Project folder created: /content/drive/MyDrive/bitcoin_project\n",
            "All project folders created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "03b639c9",
      "metadata": {
        "id": "03b639c9",
        "outputId": "daae9761-3675-4b80-d7cf-489e75dc4e2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/mczielinski/bitcoin-historical-data?dataset_version_number=406...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.7M/97.7M [00:02<00:00, 34.4MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded to: /root/.cache/kagglehub/datasets/mczielinski/bitcoin-historical-data/versions/406\n",
            "CSV files found: ['btcusd_1-min_data.csv']\n",
            "Saved btcusd_1-min_data.csv → /content/drive/MyDrive/bitcoin_project/raw/btcusd_1-min_data.csv\n"
          ]
        }
      ],
      "source": [
        "#dowload dataset\n",
        "path = kagglehub.dataset_download(\"mczielinski/bitcoin-historical-data/versions/406\")\n",
        "print(\"Downloaded to:\", path)\n",
        "\n",
        "# Find all CSV files\n",
        "csv_files = [f for f in os.listdir(path) if f.endswith(\".csv\")]\n",
        "print(\"CSV files found:\", csv_files)\n",
        "\n",
        "# Copy ALL CSVs into project/raw (NO LOCAL FOLDER)\n",
        "for f in csv_files:\n",
        "    src = os.path.join(path, f)\n",
        "    dst = f\"{PROJECT_DIR}/raw/{f}\"\n",
        "    shutil.copy(src, dst)\n",
        "    print(f\"Saved {f} → {dst}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cd77e42",
      "metadata": {
        "id": "1cd77e42"
      },
      "source": [
        "### Cleanup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1cf0ab8c",
      "metadata": {
        "id": "1cf0ab8c",
        "outputId": "456d59f2-5a41-4e2d-c88f-675a75b97335",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading: /content/drive/MyDrive/bitcoin_project/raw/btcusd_1-min_data.csv\n",
            "Cleaned file saved: /content/drive/MyDrive/bitcoin_project/cleaned/btcusd_1-min_data_no_zero_volume.csv\n"
          ]
        }
      ],
      "source": [
        "raw_file_path = f\"{PROJECT_DIR}/raw/btcusd_1-min_data.csv\"\n",
        "print(\"Loading:\", raw_file_path)\n",
        "df = pd.read_csv(raw_file_path)\n",
        "\n",
        "# Remove rows with zero volume\n",
        "df_clean = df[df[\"Volume\"] != 0].copy()\n",
        "\n",
        "clean_path = f\"{PROJECT_DIR}/cleaned/btcusd_1-min_data_no_zero_volume.csv\"\n",
        "df_clean.to_csv(clean_path, index=False)\n",
        "\n",
        "print(\"Cleaned file saved:\", clean_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ba70f403",
      "metadata": {
        "id": "ba70f403",
        "outputId": "8358880f-d8b9-4117-a268-f17ad4bdf5eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Volume threshold: 130.1700641941387\n",
            "First meaningful trading row: 1329\n",
            "Filtered file saved: /content/drive/MyDrive/bitcoin_project/filtered/btcusd_1-min_data_filtered.csv\n"
          ]
        }
      ],
      "source": [
        "# Load the cleaned (no zero-volume) file\n",
        "df = pd.read_csv(clean_path)\n",
        "\n",
        "# Use the first 30 days of data (~ 30 * 24 * 60 = 43200 rows)\n",
        "WINDOW = 43200\n",
        "initial = df.head(WINDOW)\n",
        "\n",
        "# Compute early trading threshold\n",
        "threshold = initial[\"Volume\"].mean() + 2 * initial[\"Volume\"].std()\n",
        "\n",
        "# Find the first row where volume exceeds this threshold\n",
        "start_idx = df[df[\"Volume\"] > threshold].index[0]\n",
        "\n",
        "# Keep only meaningful trading data\n",
        "df_filtered = df.loc[start_idx:].copy()\n",
        "\n",
        "# Save the result\n",
        "filtered_path = f\"{PROJECT_DIR}/filtered/btcusd_1-min_data_filtered.csv\"\n",
        "df_filtered.to_csv(filtered_path, index=False)\n",
        "\n",
        "print(\"Volume threshold:\", threshold)\n",
        "print(\"First meaningful trading row:\", start_idx)\n",
        "print(\"Filtered file saved:\", filtered_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fd289a3",
      "metadata": {
        "id": "9fd289a3"
      },
      "source": [
        "### Split the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c5988235",
      "metadata": {
        "id": "c5988235",
        "outputId": "f6d71609-7383-4c1c-b9f2-3060f666dd45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows:\n",
            "Train: 5022490\n",
            "Val: 258266\n",
            "Test: 684903\n"
          ]
        }
      ],
      "source": [
        "# Load cleaned data\n",
        "df = pd.read_csv(filtered_path)\n",
        "\n",
        "# Convert timestamp\n",
        "df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"], unit=\"s\")\n",
        "\n",
        "# Define split boundaries\n",
        "train_end = pd.Timestamp(\"2023-12-31 23:59:59\")\n",
        "val_end = pd.Timestamp(\"2024-06-30 23:59:59\")\n",
        "\n",
        "# Create splits\n",
        "df_train = df[df[\"Timestamp\"] <= train_end].copy()\n",
        "df_val   = df[(df[\"Timestamp\"] > train_end) & (df[\"Timestamp\"] <= val_end)].copy()\n",
        "df_test  = df[df[\"Timestamp\"] > val_end].copy()\n",
        "\n",
        "# Save\n",
        "df_train.to_csv(f\"{PROJECT_DIR}/splits/train_raw.csv\", index=False)\n",
        "df_val.to_csv(f\"{PROJECT_DIR}/splits/val_raw.csv\", index=False)\n",
        "df_test.to_csv(f\"{PROJECT_DIR}/splits/test_raw.csv\", index=False)\n",
        "\n",
        "print(\"Rows:\")\n",
        "print(\"Train:\", len(df_train))\n",
        "print(\"Val:\", len(df_val))\n",
        "print(\"Test:\", len(df_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7b4d2502",
      "metadata": {
        "id": "7b4d2502"
      },
      "outputs": [],
      "source": [
        "def add_indicators(df):\n",
        "    close = df[\"Close\"]\n",
        "    high = df[\"High\"]\n",
        "    low = df[\"Low\"]\n",
        "\n",
        "    # --- MACD (12, 26, 9) ---\n",
        "    macd = MACD(close=close, window_fast=12, window_slow=26, window_sign=9)\n",
        "    df[\"MACD\"] = macd.macd()\n",
        "    df[\"MACD_signal\"] = macd.macd_signal()\n",
        "\n",
        "    # --- Bollinger Band Width (20) ---\n",
        "    bb = BollingerBands(close=close, window=20, window_dev=2)\n",
        "    upper = bb.bollinger_hband()\n",
        "    lower = bb.bollinger_lband()\n",
        "    df[\"BB_width\"] = upper - lower     # band width\n",
        "\n",
        "    # --- RSI (14) ---\n",
        "    rsi = RSIIndicator(close=close, window=14)\n",
        "    df[\"RSI\"] = rsi.rsi()\n",
        "\n",
        "    # --- ATR (14) ---\n",
        "    atr = AverageTrueRange(high=high, low=low, close=close, window=14)\n",
        "    df[\"ATR\"] = atr.average_true_range()\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "dfa43b2b",
      "metadata": {
        "id": "dfa43b2b",
        "outputId": "93e9b824-68c8-413b-fa2b-a872dbb012e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'add_indicators' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2804133937.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Add indicators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_indicators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_indicators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_indicators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'add_indicators' is not defined"
          ]
        }
      ],
      "source": [
        "# Load splits\n",
        "train_path = f\"{PROJECT_DIR}/splits/train_raw.csv\"\n",
        "val_path   = f\"{PROJECT_DIR}/splits/val_raw.csv\"\n",
        "test_path  = f\"{PROJECT_DIR}/splits/test_raw.csv\"\n",
        "\n",
        "train = pd.read_csv(train_path)\n",
        "val   = pd.read_csv(val_path)\n",
        "test  = pd.read_csv(test_path)\n",
        "\n",
        "# Add indicators\n",
        "train = add_indicators(train)\n",
        "val = add_indicators(val)\n",
        "test = add_indicators(test)\n",
        "\n",
        "# Drop warm-up NaNs\n",
        "train = train.dropna().reset_index(drop=True)\n",
        "val = val.dropna().reset_index(drop=True)\n",
        "test = test.dropna().reset_index(drop=True)\n",
        "\n",
        "# Save feature-augmented data to Drive\n",
        "features_dir = f\"{PROJECT_DIR}/features\"\n",
        "os.makedirs(features_dir, exist_ok=True)\n",
        "\n",
        "train_features_path = f\"{features_dir}/train_features.csv\"\n",
        "val_features_path   = f\"{features_dir}/val_features.csv\"\n",
        "test_features_path  = f\"{features_dir}/test_features.csv\"\n",
        "\n",
        "train.to_csv(train_features_path, index=False)\n",
        "val.to_csv(val_features_path, index=False)\n",
        "test.to_csv(test_features_path, index=False)\n",
        "\n",
        "print(\"Indicators added and saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save feature-augmented data to Drive\n",
        "features_dir = f\"{PROJECT_DIR}/features\"\n",
        "os.makedirs(features_dir, exist_ok=True)\n",
        "\n",
        "train_features_path = f\"{features_dir}/train_features.csv\"\n",
        "val_features_path   = f\"{features_dir}/val_features.csv\"\n",
        "test_features_path  = f\"{features_dir}/test_features.csv\"\n"
      ],
      "metadata": {
        "id": "PMC3o8VgrSL-"
      },
      "id": "PMC3o8VgrSL-",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f9f47dfb",
      "metadata": {
        "id": "f9f47dfb"
      },
      "source": [
        "### Sliding window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8d3052e6",
      "metadata": {
        "id": "8d3052e6"
      },
      "outputs": [],
      "source": [
        "WINDOW = 60  # length of sliding window\n",
        "\n",
        "def prepare_dataset(path):\n",
        "    df = pd.read_csv(path)\n",
        "\n",
        "    # ----- Compute log return -----\n",
        "    df[\"log_return\"] = np.log(df[\"Close\"].shift(-1) / df[\"Close\"])\n",
        "    df = df.dropna().reset_index(drop=True)   # drop last row without target\n",
        "\n",
        "    # ----- Select feature columns -----\n",
        "    feature_cols = [\n",
        "        \"Close\", \"High\", \"Low\", \"Volume\",\n",
        "        \"MACD\", \"MACD_signal\",\n",
        "        \"BB_width\", \"RSI\", \"ATR\"\n",
        "    ]\n",
        "\n",
        "    data = df[feature_cols].values\n",
        "    targets = df[\"log_return\"].values\n",
        "\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for i in range(len(df) - WINDOW):\n",
        "        X.append(data[i:i+WINDOW])\n",
        "        y.append(targets[i+WINDOW])  # target = value AFTER the window\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1364d83",
      "metadata": {
        "id": "b1364d83"
      },
      "outputs": [],
      "source": [
        "# Process splits\n",
        "# Prepare train/val/test window datasets from Drive features\n",
        "train_X, train_y = prepare_dataset(train_features_path)\n",
        "val_X, val_y     = prepare_dataset(val_features_path)\n",
        "test_X, test_y   = prepare_dataset(test_features_path)\n",
        "\n",
        "windows_dir = f\"{PROJECT_DIR}/windows\"\n",
        "os.makedirs(windows_dir, exist_ok=True)\n",
        "\n",
        "np.save(f\"{windows_dir}/train_X.npy\", train_X)\n",
        "np.save(f\"{windows_dir}/train_y.npy\", train_y)\n",
        "np.save(f\"{windows_dir}/val_X.npy\", val_X)\n",
        "np.save(f\"{windows_dir}/val_y.npy\", val_y)\n",
        "np.save(f\"{windows_dir}/test_X.npy\", test_X)\n",
        "np.save(f\"{windows_dir}/test_y.npy\", test_y)\n",
        "\n",
        "\n",
        "\n",
        "print(\"Saved sliding windows!\")\n",
        "print(\"Train X shape:\", train_X.shape)\n",
        "print(\"Val X shape:\", val_X.shape)\n",
        "print(\"Test X shape:\", test_X.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2023a76",
      "metadata": {
        "id": "f2023a76"
      },
      "source": [
        "### Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1b1f7222",
      "metadata": {
        "id": "1b1f7222",
        "outputId": "55be1725-13f1-43fb-90e3-0568c4db4b74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/bitcoin_project/windows/train_X.npy'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-895231933.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load windows from Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{windows_dir}/train_X.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mval_X\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{windows_dir}/val_X.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtest_X\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{windows_dir}/test_X.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/lib/_npyio_impl.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/bitcoin_project/windows/train_X.npy'"
          ]
        }
      ],
      "source": [
        "norm_dir = f\"{PROJECT_DIR}/normalized\"\n",
        "os.makedirs(norm_dir, exist_ok=True)\n",
        "\n",
        "# Load windows from Drive\n",
        "train_X = np.load(f\"{windows_dir}/train_X.npy\")\n",
        "val_X   = np.load(f\"{windows_dir}/val_X.npy\")\n",
        "test_X  = np.load(f\"{windows_dir}/test_X.npy\")\n",
        "\n",
        "train_y = np.load(f\"{windows_dir}/train_y.npy\")\n",
        "val_y   = np.load(f\"{windows_dir}/val_y.npy\")\n",
        "test_y  = np.load(f\"{windows_dir}/test_y.npy\")\n",
        "\n",
        "# Compute mean/std over (samples, time)\n",
        "train_mean = train_X.mean(axis=(0, 1))\n",
        "train_std  = train_X.std(axis=(0, 1))\n",
        "train_std[train_std == 0] = 1e-8  # avoid division by zero\n",
        "\n",
        "def normalize(X, mean, std):\n",
        "    return (X - mean) / std\n",
        "\n",
        "train_X_norm = normalize(train_X, train_mean, train_std)\n",
        "val_X_norm   = normalize(val_X, train_mean, train_std)\n",
        "test_X_norm  = normalize(test_X, train_mean, train_std)\n",
        "\n",
        "# Save normalized datasets + stats to Drive\n",
        "np.save(f\"{norm_dir}/train_X.npy\", train_X_norm)\n",
        "np.save(f\"{norm_dir}/val_X.npy\",   val_X_norm)\n",
        "np.save(f\"{norm_dir}/test_X.npy\",  test_X_norm)\n",
        "\n",
        "np.save(f\"{norm_dir}/train_y.npy\", train_y)\n",
        "np.save(f\"{norm_dir}/val_y.npy\",   val_y)\n",
        "np.save(f\"{norm_dir}/test_y.npy\",  test_y)\n",
        "\n",
        "np.save(f\"{norm_dir}/train_mean.npy\", train_mean)\n",
        "np.save(f\"{norm_dir}/train_std.npy\",  train_std)\n",
        "\n",
        "print(\"Normalization complete!\")\n",
        "print(\"Feature count:\", train_mean.shape)\n",
        "print(\"Normalized data saved to:\", norm_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53894e27",
      "metadata": {
        "id": "53894e27"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}