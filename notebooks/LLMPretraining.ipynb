{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hetj6BWaux3",
        "outputId": "86153152-b818-43ba-cf90-1461103f1000"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sorted_nearest (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Installed Python deps and downloaded gdc-client.\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas numpy pyarrow requests tqdm pyranges --quiet\n",
        "# Download GDC client\n",
        "!wget https://gdc.cancer.gov/files/public/file/gdc-client_v1.6.1_Ubuntu_x64.zip -O gdc.zip -q\n",
        "!unzip -o gdc.zip > /dev/null\n",
        "!chmod +x gdc-client\n",
        "print(\"Installed Python deps and downloaded gdc-client.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\" Google Drive mounted at /content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S29wot_IavoE",
        "outputId": "10cfd090-4753-44fc-835c-bc4bf95fa599"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            " Google Drive mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "import pandas as pd\n",
        "from transformers import (\n",
        "    BertConfig,\n",
        "    BertForMaskedLM,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    TrainerCallback\n",
        ")\n",
        "\n",
        "# Main project root on Google Drive\n",
        "PROJECT_ROOT = Path(\"/content/drive/MyDrive/bdh_challenge_2025_data\")\n",
        "PROJECT_ROOT.mkdir(exist_ok=True)\n",
        "\n",
        "# Data directories\n",
        "DATA_DIR = PROJECT_ROOT / \"data\"\n",
        "DATA_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# Directory where raw TCGA STAR count files will be stored\n",
        "RNA_DIR = PROJECT_ROOT / \"tcga_rna\"\n",
        "RNA_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# Directory where processed matrices, tokenized data, embeddings\n",
        "PROCESSED_DIR = PROJECT_ROOT / \"processed\"\n",
        "PROCESSED_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "print(\"Project root :\", PROJECT_ROOT)\n",
        "print(\"DATA_DIR     :\", DATA_DIR)\n",
        "print(\"RNA_DIR      :\", RNA_DIR)\n",
        "print(\"PROCESSED_DIR:\", PROCESSED_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVOVdjGdb9K3",
        "outputId": "8500b3ac-6530-4bf2-97fc-9c4b776974bc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project root : /content/drive/MyDrive/bdh_challenge_2025_data\n",
            "DATA_DIR     : /content/drive/MyDrive/bdh_challenge_2025_data/data\n",
            "RNA_DIR      : /content/drive/MyDrive/bdh_challenge_2025_data/tcga_rna\n",
            "PROCESSED_DIR: /content/drive/MyDrive/bdh_challenge_2025_data/processed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ALIGNED_PATH = PROCESSED_DIR / \"tcga_tpm_like_log10_bulkrnabert_aligned.parquet\"\n",
        "expr_aligned = pd.read_parquet(ALIGNED_PATH)"
      ],
      "metadata": {
        "id": "mWU7nms7mZpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "expr_aligned"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "BXyOhWIU1PuG",
        "outputId": "b82728d9-0603-4460-a11c-76d09b9fbab4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gene_id       ENSG00000000003  ENSG00000000005  ENSG00000000419  \\\n",
              "sample_id                                                         \n",
              "TCGA-P5-A5EY         1.681527         0.063817         1.141174   \n",
              "TCGA-AR-A1AW         1.605939         0.088174         1.567791   \n",
              "TCGA-E9-A1N5         1.848499         0.367775         1.398195   \n",
              "TCGA-97-7941         2.254924         0.079794         1.397967   \n",
              "TCGA-93-7347         1.395531         0.035987         1.261120   \n",
              "...                       ...              ...              ...   \n",
              "TCGA-PQ-A6FN         1.967442         0.000000         1.796011   \n",
              "TCGA-GC-A4ZW         2.229213         0.000000         1.749333   \n",
              "TCGA-91-6840         2.262706         0.046630         1.733062   \n",
              "TCGA-AP-A052         2.188687         0.181969         1.341103   \n",
              "TCGA-AO-A03N         1.422009         0.000000         1.614042   \n",
              "\n",
              "gene_id       ENSG00000000457  ENSG00000000460  ENSG00000000938  \\\n",
              "sample_id                                                         \n",
              "TCGA-P5-A5EY         0.877901         0.408766         0.778577   \n",
              "TCGA-AR-A1AW         1.419358         1.132621         1.467036   \n",
              "TCGA-E9-A1N5         1.432945         0.981104         1.023865   \n",
              "TCGA-97-7941         1.311801         0.662706         1.375285   \n",
              "TCGA-93-7347         1.125617         0.640414         1.382043   \n",
              "...                       ...              ...              ...   \n",
              "TCGA-PQ-A6FN         0.847344         0.999576         0.946174   \n",
              "TCGA-GC-A4ZW         1.162980         1.209287         0.670079   \n",
              "TCGA-91-6840         1.263441         1.205125         1.215238   \n",
              "TCGA-AP-A052         1.046091         1.120620         0.792699   \n",
              "TCGA-AO-A03N         1.156245         0.906409         0.473160   \n",
              "\n",
              "gene_id       ENSG00000000971  ENSG00000001036  ENSG00000001084  \\\n",
              "sample_id                                                         \n",
              "TCGA-P5-A5EY         0.989684         1.165323         1.534292   \n",
              "TCGA-AR-A1AW         2.035625         1.477680         1.519647   \n",
              "TCGA-E9-A1N5         1.629135         1.540959         1.538390   \n",
              "TCGA-97-7941         1.929090         1.767373         1.938894   \n",
              "TCGA-93-7347         1.897127         1.634034         1.067374   \n",
              "...                       ...              ...              ...   \n",
              "TCGA-PQ-A6FN         1.487409         1.717826         2.103600   \n",
              "TCGA-GC-A4ZW         0.779123         2.077857         1.689240   \n",
              "TCGA-91-6840         1.586505         1.909207         1.408809   \n",
              "TCGA-AP-A052         1.627997         1.956723         1.328321   \n",
              "TCGA-AO-A03N         1.283241         1.733925         1.354266   \n",
              "\n",
              "gene_id       ENSG00000001167  ...  ENSG00000284519  ENSG00000284532  \\\n",
              "sample_id                      ...                                     \n",
              "TCGA-P5-A5EY         1.396228  ...              0.0              0.0   \n",
              "TCGA-AR-A1AW         1.800230  ...              0.0              0.0   \n",
              "TCGA-E9-A1N5         1.612078  ...              0.0              0.0   \n",
              "TCGA-97-7941         1.489701  ...              0.0              0.0   \n",
              "TCGA-93-7347         1.466133  ...              0.0              0.0   \n",
              "...                       ...  ...              ...              ...   \n",
              "TCGA-PQ-A6FN         1.397338  ...              0.0              0.0   \n",
              "TCGA-GC-A4ZW         1.659367  ...              0.0              0.0   \n",
              "TCGA-91-6840         1.954489  ...              0.0              0.0   \n",
              "TCGA-AP-A052         1.524276  ...              0.0              0.0   \n",
              "TCGA-AO-A03N         1.733482  ...              0.0              0.0   \n",
              "\n",
              "gene_id       ENSG00000284535  ENSG00000284543  ENSG00000284557  \\\n",
              "sample_id                                                         \n",
              "TCGA-P5-A5EY              0.0         0.008509              0.0   \n",
              "TCGA-AR-A1AW              0.0         0.254434              0.0   \n",
              "TCGA-E9-A1N5              0.0         0.189368              0.0   \n",
              "TCGA-97-7941              0.0         0.393385              0.0   \n",
              "TCGA-93-7347              0.0         0.241292              0.0   \n",
              "...                       ...              ...              ...   \n",
              "TCGA-PQ-A6FN              0.0         0.108074              0.0   \n",
              "TCGA-GC-A4ZW              0.0         1.530551              0.0   \n",
              "TCGA-91-6840              0.0         0.088735              0.0   \n",
              "TCGA-AP-A052              0.0         0.069476              0.0   \n",
              "TCGA-AO-A03N              0.0         0.038296              0.0   \n",
              "\n",
              "gene_id       ENSG00000284564  ENSG00000284574  ENSG00000284587  \\\n",
              "sample_id                                                         \n",
              "TCGA-P5-A5EY              0.0              0.0              0.0   \n",
              "TCGA-AR-A1AW              0.0              0.0              0.0   \n",
              "TCGA-E9-A1N5              0.0              0.0              0.0   \n",
              "TCGA-97-7941              0.0              0.0              0.0   \n",
              "TCGA-93-7347              0.0              0.0              0.0   \n",
              "...                       ...              ...              ...   \n",
              "TCGA-PQ-A6FN              0.0              0.0              0.0   \n",
              "TCGA-GC-A4ZW              0.0              0.0              0.0   \n",
              "TCGA-91-6840              0.0              0.0              0.0   \n",
              "TCGA-AP-A052              0.0              0.0              0.0   \n",
              "TCGA-AO-A03N              0.0              0.0              0.0   \n",
              "\n",
              "gene_id       ENSG00000284595  ENSG00000284596  \n",
              "sample_id                                       \n",
              "TCGA-P5-A5EY              0.0              0.0  \n",
              "TCGA-AR-A1AW              0.0              0.0  \n",
              "TCGA-E9-A1N5              0.0              0.0  \n",
              "TCGA-97-7941              0.0              0.0  \n",
              "TCGA-93-7347              0.0              0.0  \n",
              "...                       ...              ...  \n",
              "TCGA-PQ-A6FN              0.0              0.0  \n",
              "TCGA-GC-A4ZW              0.0              0.0  \n",
              "TCGA-91-6840              0.0              0.0  \n",
              "TCGA-AP-A052              0.0              0.0  \n",
              "TCGA-AO-A03N              0.0              0.0  \n",
              "\n",
              "[3385 rows x 19062 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1f7044d5-cdd0-40ec-8eb0-2cdcea4be712\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>gene_id</th>\n",
              "      <th>ENSG00000000003</th>\n",
              "      <th>ENSG00000000005</th>\n",
              "      <th>ENSG00000000419</th>\n",
              "      <th>ENSG00000000457</th>\n",
              "      <th>ENSG00000000460</th>\n",
              "      <th>ENSG00000000938</th>\n",
              "      <th>ENSG00000000971</th>\n",
              "      <th>ENSG00000001036</th>\n",
              "      <th>ENSG00000001084</th>\n",
              "      <th>ENSG00000001167</th>\n",
              "      <th>...</th>\n",
              "      <th>ENSG00000284519</th>\n",
              "      <th>ENSG00000284532</th>\n",
              "      <th>ENSG00000284535</th>\n",
              "      <th>ENSG00000284543</th>\n",
              "      <th>ENSG00000284557</th>\n",
              "      <th>ENSG00000284564</th>\n",
              "      <th>ENSG00000284574</th>\n",
              "      <th>ENSG00000284587</th>\n",
              "      <th>ENSG00000284595</th>\n",
              "      <th>ENSG00000284596</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sample_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>TCGA-P5-A5EY</th>\n",
              "      <td>1.681527</td>\n",
              "      <td>0.063817</td>\n",
              "      <td>1.141174</td>\n",
              "      <td>0.877901</td>\n",
              "      <td>0.408766</td>\n",
              "      <td>0.778577</td>\n",
              "      <td>0.989684</td>\n",
              "      <td>1.165323</td>\n",
              "      <td>1.534292</td>\n",
              "      <td>1.396228</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008509</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-AR-A1AW</th>\n",
              "      <td>1.605939</td>\n",
              "      <td>0.088174</td>\n",
              "      <td>1.567791</td>\n",
              "      <td>1.419358</td>\n",
              "      <td>1.132621</td>\n",
              "      <td>1.467036</td>\n",
              "      <td>2.035625</td>\n",
              "      <td>1.477680</td>\n",
              "      <td>1.519647</td>\n",
              "      <td>1.800230</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.254434</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-E9-A1N5</th>\n",
              "      <td>1.848499</td>\n",
              "      <td>0.367775</td>\n",
              "      <td>1.398195</td>\n",
              "      <td>1.432945</td>\n",
              "      <td>0.981104</td>\n",
              "      <td>1.023865</td>\n",
              "      <td>1.629135</td>\n",
              "      <td>1.540959</td>\n",
              "      <td>1.538390</td>\n",
              "      <td>1.612078</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.189368</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-97-7941</th>\n",
              "      <td>2.254924</td>\n",
              "      <td>0.079794</td>\n",
              "      <td>1.397967</td>\n",
              "      <td>1.311801</td>\n",
              "      <td>0.662706</td>\n",
              "      <td>1.375285</td>\n",
              "      <td>1.929090</td>\n",
              "      <td>1.767373</td>\n",
              "      <td>1.938894</td>\n",
              "      <td>1.489701</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.393385</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-93-7347</th>\n",
              "      <td>1.395531</td>\n",
              "      <td>0.035987</td>\n",
              "      <td>1.261120</td>\n",
              "      <td>1.125617</td>\n",
              "      <td>0.640414</td>\n",
              "      <td>1.382043</td>\n",
              "      <td>1.897127</td>\n",
              "      <td>1.634034</td>\n",
              "      <td>1.067374</td>\n",
              "      <td>1.466133</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.241292</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-PQ-A6FN</th>\n",
              "      <td>1.967442</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.796011</td>\n",
              "      <td>0.847344</td>\n",
              "      <td>0.999576</td>\n",
              "      <td>0.946174</td>\n",
              "      <td>1.487409</td>\n",
              "      <td>1.717826</td>\n",
              "      <td>2.103600</td>\n",
              "      <td>1.397338</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.108074</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-GC-A4ZW</th>\n",
              "      <td>2.229213</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.749333</td>\n",
              "      <td>1.162980</td>\n",
              "      <td>1.209287</td>\n",
              "      <td>0.670079</td>\n",
              "      <td>0.779123</td>\n",
              "      <td>2.077857</td>\n",
              "      <td>1.689240</td>\n",
              "      <td>1.659367</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.530551</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-91-6840</th>\n",
              "      <td>2.262706</td>\n",
              "      <td>0.046630</td>\n",
              "      <td>1.733062</td>\n",
              "      <td>1.263441</td>\n",
              "      <td>1.205125</td>\n",
              "      <td>1.215238</td>\n",
              "      <td>1.586505</td>\n",
              "      <td>1.909207</td>\n",
              "      <td>1.408809</td>\n",
              "      <td>1.954489</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.088735</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-AP-A052</th>\n",
              "      <td>2.188687</td>\n",
              "      <td>0.181969</td>\n",
              "      <td>1.341103</td>\n",
              "      <td>1.046091</td>\n",
              "      <td>1.120620</td>\n",
              "      <td>0.792699</td>\n",
              "      <td>1.627997</td>\n",
              "      <td>1.956723</td>\n",
              "      <td>1.328321</td>\n",
              "      <td>1.524276</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.069476</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-AO-A03N</th>\n",
              "      <td>1.422009</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.614042</td>\n",
              "      <td>1.156245</td>\n",
              "      <td>0.906409</td>\n",
              "      <td>0.473160</td>\n",
              "      <td>1.283241</td>\n",
              "      <td>1.733925</td>\n",
              "      <td>1.354266</td>\n",
              "      <td>1.733482</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038296</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3385 rows Ã— 19062 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f7044d5-cdd0-40ec-8eb0-2cdcea4be712')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1f7044d5-cdd0-40ec-8eb0-2cdcea4be712 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1f7044d5-cdd0-40ec-8eb0-2cdcea4be712');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-eaaffea0-a7f7-447b-89f3-7acb7fea57ff\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eaaffea0-a7f7-447b-89f3-7acb7fea57ff')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-eaaffea0-a7f7-447b-89f3-7acb7fea57ff button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_4f7e3bf9-d485-4bfc-b9a9-c6e420925ade\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('expr_aligned')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4f7e3bf9-d485-4bfc-b9a9-c6e420925ade button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('expr_aligned');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "expr_aligned"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertConfig, BertForMaskedLM, PreTrainedModel, BertModel\n",
        "\n",
        "CONFIG = {\n",
        "    \"N_genes\": 19062,\n",
        "    \"n_embedding\": 256,\n",
        "    \"n_layers\": 4,\n",
        "    \"n_heads\": 8,\n",
        "    \"n_bins\": 64,\n",
        "    \"vocab_size\": 70,\n",
        "    \"mask_prob\": 0.15,\n",
        "    \"batch_size_eff\": 3e6,\n",
        "    \"batch_size\": 16,\n",
        "    \"hv_genes_count\": 12403,\n",
        "    \"grad_accum\": 4,\n",
        "    \"lr\": 1e-4,\n",
        "    \"max_steps\": 10000,\n",
        "}"
      ],
      "metadata": {
        "id": "IAM1JO881Pq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNAPreprocessor:\n",
        "    def __init__(self, num_bins=64):\n",
        "        self.num_bins = num_bins\n",
        "        self.global_max = None\n",
        "        self.bin_edges = None\n",
        "\n",
        "    def fit_transform(self, data):\n",
        "\n",
        "        # 1. Log Transform\n",
        "        transformed = data # np.log10(1 + data)\n",
        "\n",
        "        # 2. Max Normalization (Global)\n",
        "        self.global_max = np.max(transformed)\n",
        "        normalized = transformed / self.global_max\n",
        "\n",
        "        # 3. Binning\n",
        "        self.bin_edges = np.linspace(0, 1, self.num_bins + 1)\n",
        "        binned = np.digitize(normalized, self.bin_edges) - 1\n",
        "        binned = np.clip(binned, 0, self.num_bins - 1)\n",
        "\n",
        "        # Shift +5 for special tokens (0-4 reserved)\n",
        "        return binned + 5\n",
        "\n",
        "class BulkRNADataset(Dataset):\n",
        "    def __init__(self, tokenized_data, survival_time=None, event_indicator=None):\n",
        "        self.data = torch.tensor(tokenized_data, dtype=torch.long)\n",
        "        self.survival_time = torch.tensor(survival_time, dtype=torch.float) if survival_time is not None else None\n",
        "        self.event = torch.tensor(event_indicator, dtype=torch.float) if event_indicator is not None else None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {\"input_ids\": self.data[idx]}\n",
        "        if self.survival_time is not None:\n",
        "            item[\"time\"] = self.survival_time[idx]\n",
        "            item[\"event\"] = self.event[idx]\n",
        "        return item"
      ],
      "metadata": {
        "id": "Cxm3DugB1PoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. PRE-TRAINING (Masked Language Model)\n",
        "\n",
        "class MockTokenizer:\n",
        "    \"\"\"\n",
        "    A dummy tokenizer that satisfies all DataCollator requirements:\n",
        "    1. Provides special token attributes.\n",
        "    2. Implements padding (stacking tensors).\n",
        "    3. Identifies special tokens so they aren't masked.\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, mask_token_id=4, pad_token_id=0):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.mask_token_id = mask_token_id\n",
        "        self.pad_token_id = pad_token_id\n",
        "\n",
        "        # Attributes required by DataCollator checks\n",
        "        self.mask_token = \"[MASK]\"\n",
        "        self.pad_token = \"[PAD]\"\n",
        "\n",
        "        # Prevents truncation warnings\n",
        "        self.model_max_length = 100_000\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.vocab_size\n",
        "\n",
        "    def pad(self, encoded_inputs, return_tensors=\"pt\", **kwargs):\n",
        "        \"\"\"\n",
        "        Called by DataCollator to stack a list of samples into a batch.\n",
        "        Since our gene expression data is fixed-length (N_genes), we just stack them.\n",
        "        \"\"\"\n",
        "        import torch\n",
        "\n",
        "        # encoded_inputs is a list of dicts: [{'input_ids': tensor}, {'input_ids': tensor}]\n",
        "        batch = {}\n",
        "\n",
        "        # We take the first sample to know the keys (usually just 'input_ids')\n",
        "        for key in encoded_inputs[0].keys():\n",
        "            # Extract values for this key from all samples\n",
        "            values = [d[key] for d in encoded_inputs]\n",
        "\n",
        "            # If they are already tensors, stack them. If lists, convert to tensor.\n",
        "            if isinstance(values[0], torch.Tensor):\n",
        "                batch[key] = torch.stack(values)\n",
        "            else:\n",
        "                batch[key] = torch.tensor(values, dtype=torch.long)\n",
        "\n",
        "        return batch\n",
        "\n",
        "    def get_special_tokens_mask(self, token_ids_0, token_ids_1=None, already_has_special_tokens=False):\n",
        "        \"\"\"\n",
        "        Called by DataCollator to decide what NOT to mask.\n",
        "        We treat IDs 0 to 4 as special (PAD, UNK, CLS, SEP, MASK).\n",
        "        Returns: list of 0s (can mask) and 1s (cannot mask).\n",
        "        \"\"\"\n",
        "        # token_ids_0 is a list of integers\n",
        "        return [1 if token < 5 else 0 for token in token_ids_0]\n",
        "\n",
        "    def convert_tokens_to_ids(self, token):\n",
        "        return self.mask_token_id if token == self.mask_token else 0\n",
        "\n",
        "    def save_pretrained(self, save_directory):\n",
        "        pass\n",
        "\n",
        "def train_pretraining_model(train_dataset, eval_dataset):\n",
        "    \"\"\"\n",
        "    Sets up the BERT MLM training loop using Hugging Face Trainer.\n",
        "    Matches the \"Pre-training\" section of the paper.\n",
        "    \"\"\"\n",
        "    tokenizer = MockTokenizer(\n",
        "        vocab_size=CONFIG['vocab_size'],\n",
        "        mask_token_id=4,\n",
        "        pad_token_id=0\n",
        "    )\n",
        "    # 1. Architecture\n",
        "    config = BertConfig(\n",
        "        vocab_size=CONFIG['vocab_size'],\n",
        "        hidden_size=CONFIG['n_embedding'],\n",
        "        num_hidden_layers=CONFIG['n_layers'],\n",
        "        num_attention_heads=CONFIG['n_heads'],\n",
        "        max_position_embeddings=CONFIG['N_genes'] + 512, # Buffer\n",
        "        pad_token_id=0,\n",
        "        mask_token_id=4\n",
        "    )\n",
        "\n",
        "    model = BertForMaskedLM(config)\n",
        "    print(f\"Model Parameters: {model.num_parameters()}\")\n",
        "\n",
        "    # 2. Collator (Handles the 15% masking automatically)\n",
        "    # Paper: \"decided not to consider only non-zero... but all of them\"\n",
        "    data_collator = DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer, # Not needed for custom IDs\n",
        "        mlm=True,\n",
        "        mlm_probability=CONFIG['mask_prob']\n",
        "    )\n",
        "\n",
        "    # 3. Training Arguments\n",
        "    # Paper uses huge batch size (3e6 tokens). We simulate via accumulation.\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./results_pretrain\",\n",
        "        overwrite_output_dir=True,\n",
        "        num_train_epochs=15,\n",
        "        per_device_train_batch_size=CONFIG['batch_size'],\n",
        "        gradient_accumulation_steps=CONFIG['grad_accum'],\n",
        "        learning_rate=CONFIG['lr'],\n",
        "        logging_steps=50,\n",
        "        save_steps=500,\n",
        "        eval_strategy=\"steps\",\n",
        "        eval_steps=100,\n",
        "        fp16=torch.cuda.is_available(), # Use mixed precision if GPU available\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "\n",
        "    # 4. Metrics (Reconstruction Accuracy)\n",
        "    def compute_metrics(eval_pred):\n",
        "        logits, labels = eval_pred\n",
        "        predictions = np.argmax(logits, axis=-1)\n",
        "        # Masked tokens are those where label != -100\n",
        "        mask = labels != -100\n",
        "        accuracy = (predictions[mask] == labels[mask]).mean()\n",
        "        return {\"accuracy\": accuracy}\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=eval_dataset,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    return trainer"
      ],
      "metadata": {
        "id": "HJPUBT_W1Pk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "print(\"\\nPreprocessing Data...\")\n",
        "preprocessor = RNAPreprocessor(num_bins=CONFIG['n_bins'])\n",
        "tokenized_data = preprocessor.fit_transform(expr_aligned)\n",
        "\n",
        "# Split Train/Test (95/5 split as per paper)\n",
        "train_data, test_data = train_test_split(tokenized_data, test_size=0.05)\n",
        "\n",
        "train_dataset = BulkRNADataset(train_data)\n",
        "eval_dataset = BulkRNADataset(test_data)\n",
        "\n",
        "print(f\"Train size: {len(train_dataset)}, Eval size: {len(eval_dataset)}\")\n",
        "\n",
        "# --- PART C: Pre-train (MLM) ---\n",
        "print(\"\\nStarting Pre-training...\")\n",
        "trainer = train_pretraining_model(train_dataset, eval_dataset)\n",
        "\n",
        "# Run Training\n",
        "trainer.train() # Uncomment to execute\n",
        "print(\"Training setup complete. Call trainer.train() to start.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "5Qky2XQU1PiU",
        "outputId": "5b8db5b2-4387-4411-ba93-3cb1e59d8da4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Preprocessing Data...\n",
            "Train size: 3215, Eval size: 170\n",
            "\n",
            "Starting Pre-training...\n",
            "Model Parameters: 12457798\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='12' max='765' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 12/765 00:43 < 54:00, 0.23 it/s, Epoch 0.22/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1080593125.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Run Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Uncomment to execute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training setup complete. Call trainer.train() to start.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2324\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2325\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2326\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2327\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2677\u001b[0m                         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2678\u001b[0m                         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_xla_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2679\u001b[0;31m                         \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2680\u001b[0m                     ):\n\u001b[1;32m   2681\u001b[0m                         \u001b[0;31m# if loss is nan or inf simply add the average of previous logged losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel, BertConfig\n",
        "\n",
        "\n",
        "checkpoint_path = PROJECT_ROOT /\"BulkRNABert_Models/checkpoint-765\"\n",
        "\n",
        "model_mlm = BertForMaskedLM.from_pretrained(checkpoint_path)\n",
        "bert_encoder = BertModel.from_pretrained(checkpoint_path)\n",
        "\n",
        "print(\"Encoder loaded successfully. Ready for fine-tuning.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuursgVB1PfM",
        "outputId": "d92ba1c6-763d-4ed4-f96b-5f01f77eb6a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at /content/drive/MyDrive/bdh_challenge_2025_data/BulkRNABert_Models/checkpoint-765 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder loaded successfully. Ready for fine-tuning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_encoder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAlFCNzfaNJ3",
        "outputId": "c31d0d52-7bc9-4fd1-952d-39bd240f4631"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(70, 256, padding_idx=0)\n",
              "    (position_embeddings): Embedding(19574, 256)\n",
              "    (token_type_embeddings): Embedding(2, 256)\n",
              "    (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-3): 4 x BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSdpaSelfAttention(\n",
              "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=256, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=256, bias=True)\n",
              "          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "def plot_logs_from_history(log_history, batch_size_per_device, grad_accum_steps, seq_len=19042):\n",
        "    \"\"\"\n",
        "    Parses the standard HF Trainer log format provided and plots:\n",
        "    1. Training Loss (Left Axis)\n",
        "    2. Eval Accuracy (Right Axis)\n",
        "    vs Number of Tokens.\n",
        "    \"\"\"\n",
        "    # Calculate effective batch size in tokens\n",
        "    # Tokens per Step = Batch * GradAccum * SeqLen\n",
        "    tokens_per_step = batch_size_per_device * grad_accum_steps * seq_len\n",
        "\n",
        "    # Extract data\n",
        "    train_data = {'tokens': [], 'value': []}\n",
        "    eval_data = {'tokens': [], 'value': []}\n",
        "\n",
        "    for entry in log_history:\n",
        "        if 'step' not in entry:\n",
        "            continue\n",
        "\n",
        "        current_tokens = entry['step'] * tokens_per_step\n",
        "\n",
        "        # 1. Capture Training Loss\n",
        "        if 'loss' in entry:\n",
        "            train_data['tokens'].append(current_tokens)\n",
        "            train_data['value'].append(entry['loss'])\n",
        "\n",
        "        # 2. Capture Eval Accuracy\n",
        "        elif 'eval_accuracy' in entry:\n",
        "            eval_data['tokens'].append(current_tokens)\n",
        "            eval_data['value'].append(entry['eval_accuracy'])\n",
        "\n",
        "    # Convert to DataFrames\n",
        "    df_train = pd.DataFrame(train_data)\n",
        "    df_eval = pd.DataFrame(eval_data)\n",
        "\n",
        "    # --- Plotting ---\n",
        "    sns.set_style(\"whitegrid\")\n",
        "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "    # Plot Training Loss (Left Y-Axis)\n",
        "    color_loss = 'tab:blue'\n",
        "    sns.lineplot(\n",
        "        data=df_train, x='tokens', y='value',\n",
        "        ax=ax1, color=color_loss, label='Training Loss', alpha=0.6\n",
        "    )\n",
        "    ax1.set_xlabel('Number of Training Tokens (1e10)', fontsize=12)\n",
        "    ax1.set_ylabel('Training Loss', color=color_loss, fontsize=12)\n",
        "    ax1.tick_params(axis='y', labelcolor=color_loss)\n",
        "    ax1.grid(False) # Turn off grid for primary to avoid clutter\n",
        "\n",
        "    # Create Twin Axis for Accuracy (Right Y-Axis)\n",
        "    ax2 = ax1.twinx()\n",
        "    color_acc = 'tab:magenta' # Matching the paper's color for test\n",
        "\n",
        "    if not df_eval.empty:\n",
        "        sns.lineplot(\n",
        "            data=df_eval, x='tokens', y='value',\n",
        "            ax=ax2, color=color_acc, label='Validation Accuracy', linewidth=2.5, marker='o'\n",
        "        )\n",
        "\n",
        "    ax2.set_ylabel('Accuracy', color=color_acc, fontsize=12)\n",
        "    ax2.tick_params(axis='y', labelcolor=color_acc)\n",
        "    ax2.set_ylim(0, 1.0) # Accuracy is 0-1\n",
        "\n",
        "    # Title and formatting\n",
        "    plt.title('BulkRNABert Training Progress', fontsize=14)\n",
        "    plt.ticklabel_format(style='sci', axis='x', scilimits=(0,0)) # Scientific notation for tokens\n",
        "\n",
        "    # Combine legends\n",
        "    lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
        "    lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
        "    ax2.legend(lines_1 + lines_2, labels_1 + labels_2, loc='upper left')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# CONFIG parameters (Make sure these match your training run!)\n",
        "BATCH_SIZE = 8   # per_device_train_batch_size\n",
        "GRAD_ACCUM = 4   # gradient_accumulation_steps\n",
        "SEQ_LEN = 19042  # N_genes\n",
        "\n",
        "plot_logs_from_history(trainer.state.log_history, BATCH_SIZE, GRAD_ACCUM, SEQ_LEN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770
        },
        "id": "Fi68sD6a1PZP",
        "outputId": "b807892e-8048-47d5-d83e-7c7743f12397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "'tab:magenta' is not a valid value for color: supported inputs are (r, g, b) and (r, g, b, a) 0-1 float tuples; '#rrggbb', '#rrggbbaa', '#rgb', '#rgba' strings; named color strings; string reprs of 0-1 floats for grayscale values; 'C0', 'C1', ... strings for colors of the color cycle; and pairs combining one of the above with an alpha value",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-334748377.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0mSEQ_LEN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m19042\u001b[0m  \u001b[0;31m# N_genes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m \u001b[0mplot_logs_from_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGRAD_ACCUM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSEQ_LEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-334748377.py\u001b[0m in \u001b[0;36mplot_logs_from_history\u001b[0;34m(log_history, batch_size_per_device, grad_accum_steps, seq_len)\u001b[0m\n\u001b[1;32m     63\u001b[0m         )\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0max2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0max2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0max2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Accuracy is 0-1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mset_ylabel\u001b[0;34m(self, ylabel, fontdict, labelpad, loc, **kwargs)\u001b[0m\n\u001b[1;32m   3851\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhorizontalalignment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3853\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3855\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvert_yaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mset_label_text\u001b[0;34m(self, label, fontdict, **kwargs)\u001b[0m\n\u001b[1;32m   1911\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfontdict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1912\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfontdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1913\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1914\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;31m# Update bbox last, as it depends on font properties.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentinel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msentinel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_bbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, props)\u001b[0m\n\u001b[1;32m   1221\u001b[0m         \u001b[0mprops\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \"\"\"\n\u001b[0;32m-> 1223\u001b[0;31m         return self._update_props(\n\u001b[0m\u001b[1;32m   1224\u001b[0m             props, \"{cls.__name__!r} object has no property {prop_name!r}\")\n\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36m_update_props\u001b[0;34m(self, props, errfmt)\u001b[0m\n\u001b[1;32m   1207\u001b[0m                             \u001b[0merrfmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprop_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                             name=k)\n\u001b[0;32m-> 1209\u001b[0;31m                     \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpchanged\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mset_color\u001b[0;34m(self, color)\u001b[0m\n\u001b[1;32m   1004\u001b[0m         \u001b[0;31m# out at draw time for simplicity.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m             \u001b[0mmpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_color_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_color\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36m_check_color_like\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_color_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    249\u001b[0m                 \u001b[0;34mf\"{v!r} is not a valid value for {k}: supported inputs are \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                 \u001b[0;34mf\"(r, g, b) and (r, g, b, a) 0-1 float tuples; \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: 'tab:magenta' is not a valid value for color: supported inputs are (r, g, b) and (r, g, b, a) 0-1 float tuples; '#rrggbb', '#rrggbbaa', '#rgb', '#rgba' strings; named color strings; string reprs of 0-1 floats for grayscale values; 'C0', 'C1', ... strings for colors of the color cycle; and pairs combining one of the above with an alpha value"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABDQAAAIWCAYAAACoWt19AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAX0pJREFUeJzt3Xt8j/X/x/HnZ4fPhh1tc54zwwxzSM45dEAlckghklMOJd+ISlSSQhKVQ+TUN76iFKmodDAqxzlEzsxpmzGbbZ9tn8/vDz+f+tjM9rGZa3vcbze3m+t9va/39bq4vn1dz72v92Wy2Ww2AQAAAAAAGIhLfhcAAAAAAACQUwQaAAAAAADAcAg0AAAAAACA4RBoAAAAAAAAwyHQAAAAAAAAhkOgAQAAAAAADIdAAwAAAAAAGA6BBgAAAAAAMBwCDQAAAAAAYDgEGgAAAAAAwHAINAAAAAAAKGT++OMPDR48WM2bN1dISIg2bNhw02O2bt2qzp07q3bt2rr33nu1atWq21DpjRFoAAAAAABQyFy5ckUhISF69dVXs9X/5MmTGjRokBo3bqwvv/xSTz75pF5++WX98ssveVzpjbnl25kBAAAAAEC+aNWqlVq1apXt/p999pnKlSunF198UZJUpUoVbdu2TZ988olatGiRV2VmiUAjD6SlpSk5OVlubm5ycWESDAAAAAAgb1mtViUlJclkMsnN7Z9HfbPZLLPZfMvj79y5U02aNHFoa968ud58881bHttZBBp5IDk5WQcOHMjvMgAAAAAAhczQoUMVFxdn3x42bJiGDx9+y+PGxMQoMDDQoS0wMFAJCQlKTk6Wp6fnLZ8jpwg08sC1NKxq1aq5koQBAAAAAJAVi8WiQ4cOae3atfLw8LC3F+RnUgKNPHDtNZMiRYoU6JsHAAAAAHBncHV1lSR5e3vnyXNoYGCgYmJiHNpiYmLk5eWVL7MzJL5yAgAAAAAAbqJevXrasmWLQ9vmzZtVr169/ClIBBoAAAAAABQ6iYmJ2r9/v/bv3y9JOnXqlPbv36/Tp09LkqZNm6bRo0fb+z/22GM6efKk3n77bR0+fFjLli3TN998o759++ZH+ZJ45QQAAAAAgEJnz5496tOnj3178uTJkqTOnTvrrbfeUnR0tM6cOWPfHxwcrDlz5mjy5MlavHixSpUqpTfeeCPfPtkqSSabzWbLt7MXUBaLRZGRkQoLC2MNDQAAAAA3ZbPZlJaWpvT09PwuBXcoV1dXubm5yWQyZbq/MD6HMkMDAAAAAPKRxWLRmTNndOXKlfwuBXe4okWLqnTp0oUmsLgZAg0AAAAAyCdWq1VHjx6Vq6urypQpI7PZfMOfwKPwstlsslgsio6O1tGjR1WtWjX71zULMwINAAAAAMgnFotFVqtVwcHBKlq0aH6XgztYkSJF5O7uruPHj8tiseTbp1LvJEQ6AAAAAJDP+Gk7soP7xBF/GgAAAAAAwHAINAAAAAAAgOEQaAAAAAAA8l2bNm30ySefZLv/1q1bFRISovj4+LwrCnc0FgUFAAAAAGRbSEhIlvuHDRum4cOH53jclStXqkiRItnuHx4erl9//VXe3t45PldObN26VX369NEff/whHx+fPD0XcoZAAwAAAACQbb/++qv99+vWrdPMmTO1fv16e9u/v9Zis9mUnp4uN7ebP3oWL148R3WYzWYFBQXl6BgULLxyAgAAAAB3GJvNppS09Nv2y2azZbu2oKAg+y9vb2+ZTCb79pEjR1S/fn1t2rRJXbp0UVhYmLZt26YTJ05oyJAhatq0qcLDw/Xoo49q8+bNDuNe/8pJSEiI/ve//2no0KGqW7eu7rvvPm3cuNG+//pXTlatWqWGDRvql19+Ufv27RUeHq7+/fvr/Pnz9mPS0tL0xhtvqGHDhmrcuLHeeecdjRkzRs8884yTf1PSpUuXNHr0aDVq1Eh169bV008/rWPHjtn3R0VFafDgwWrUqJHq1aunjh07atOmTfZjR40apbvvvlt16tTRfffdp88//9zpWgobZmgAAAAAwB3EZrNpzs9HdDz2ym07Z4WAohrUsrJMJlOujDdt2jSNGTNGwcHB8vHx0dmzZ9WqVSuNHDlSZrNZX3zxhQYPHqz169erTJkyNxxn1qxZeuGFFzR69GgtWbJE//nPf/Tjjz/Kz88v0/7JyclasGCB3n77bbm4uOiFF17QlClTNG3aNEnSvHnz9NVXX2ny5MmqXLmyFi9erA0bNqhx48ZOX+uLL76o48eP68MPP5SXl5feeecdDRw4UGvXrpW7u7tee+01paamaunSpSpatKgOHTpkn8Xy3nvv6fDhw5o3b578/f114sQJJScnO11LYUOgAQAAAADIVSNGjFCzZs3s235+fqpRo4Z9+7nnntOGDRv0ww8/qFevXjccp3PnznrwwQclSc8//7yWLFmi3bt3q2XLlpn2T01N1cSJE1W+fHlJ0hNPPKEPPvjAvn/p0qUaOHCg7r33XknS+PHj9fPPPzt9nceOHdMPP/yg//73v6pfv74kaerUqbrnnnu0YcMGtW/fXqdPn9b9999vX3skODjYfvzp06dVs2ZNhYWFSZLKlSvndC2FEYEGAAAAANxBTCaTBrWsLEu69bad0+zqkmuzMyTZH9CvSUxM1KxZs/TTTz8pOjpa6enpSk5O1unTp7Mc598LkBYtWlReXl66cOHCDfsXKVLEHmZIUokSJRQbGytJunz5smJiYlSnTh37fldXV4WGhspqde7P+vDhw3Jzc1PdunXtbf7+/qpUqZIOHz4sSerTp48mTJigX3/9VU2bNtV9991nD3d69uypESNGaN++fWrWrJnatWtnD0Zwc6yhAQAAAAB3GJPJJA8319v2KzfDDEkZvlYyZcoUff/993r++ee1bNkyffHFF6pevbpSU1OzHMfd3T3Dn0tW4cP1i4+aTKYcrQ+SF7p166YNGzaoU6dOOnjwoLp27aolS5ZIklq1aqUff/xRffv21fnz59W3b19NmTIlX+s1EgINAAAAAECe2rFjhzp37qx7771XISEhCgwMVFRU1G2twdvbW4GBgYqMjLS3paena9++fU6PWaVKFaWlpWnXrl32tri4OB09elRVq1a1t5UuXVo9e/bUrFmz1K9fP61YscK+r3jx4urcubOmTp2qcePGafny5U7XU9jwygkAAAAAIE9VqFBB33//vdq0aSOTyaQZM2Y4/ZrHrejVq5fmzJmj8uXLq3Llylq6dKkuXbqUrRkqBw8eVLFixezbJpNJNWrUUNu2bfXKK69o4sSJ8vLy0tSpU1WyZEm1bdtWkjRp0iS1bNlSFStWVHx8vLZu3aoqVapIurooaGhoqKpVqyaLxaKffvrJvg83R6ABAAAAAMhTL774osaNG6fHHntM/v7+GjBggBITE297HQMGDFBMTIzGjBkjV1dXde/eXc2bN5erq+tNj33iiScctl1dXbVv3z5NnjxZkyZN0uDBg5WamqqGDRtq7ty59tdlrFarXnvtNZ09e1ZeXl5q0aKFxo4dK+nqKzXTp09XVFSUPD091aBBA02fPj33L7yAMtny+4WiAshisSgyMlJhYWEym835XQ4AAACAO1RycrKOHj2qSpUqydPTM7/LKXSsVqvat2+v9u3b67nnnsvvcm4qq/ulMD6HMkMDAAAAAFAoREVF6bffflOjRo1ksVi0bNkyRUVF6aGHHsrv0uAEAg0AAAAAQKHg4uKiVatWacqUKbLZbKpevboWLlzIuhUGRaABAAAAACgUSpcurc8++yy/y0Au4bOtAAAAAADAcAg0AAAAACCf8a0GZAf3iSMCDQAAAADIJ9c+7XnlypV8rgRGcO0+uXbfFHasoQEAAAAA+cTV1VV+fn46f/68JKlo0aIymUz5XBXuNDabTVeuXNH58+fl5+cnV1fX/C7pjkCgAQAAAAD5qFSpUpJkDzWAG/Hz87PfLyDQAAAAAIB8ZTKZVLp0aZUoUUKpqan5XQ7uUO7u7szMuA6BBgAAAADcAVxdXXlgBXKARUEBAAAAAIDhEGgAAAAAAADDIdAAAAAAAACGQ6ABAAAAAAAMh0ADAAAAAAAYDoEGAAAAAAAwHAINAAAAAABgOAQaAAAAAADAcAg0AAAAAACA4RBoAAAAAAAAwyHQAAAAAAAAhkOgAQAAAAAADIdAAwAAAAAAGA6BBgAAAAAAMBwCDQAAAAAAYDgEGgAAAAAAwHAINAAAAAAAgOEQaAAAAAAAAMMh0AAAAAAAAIZDoAEAAAAAAAyHQAMAAAAAABgOgQYAAAAAADAcAg0AAAAAAGA4BBoAAAAAAMBw3PK7gFu1OOKY5mw6ouiEFNUs7aOJD4eqXrDfDfuv3X1G074/oFNxSaoUUEwvtq+h1jVKZNp33OpIfbr1hF55sJb6N6+UR1cAAAAAAAByytAzNL7adVpvfL1fz7arprXDm6tWaW/1+XirYhJSMu2/7fgFjfhsh3o0DNa6Ec11X2hJDVzypw6cvZyh7/o9Z7XjxEWV9PHI68sAAAAAAAA5ZOhAY/6vR/XYXcHq3jBY1Up6a9IjYSpidtWKP09m2n/Bb8fUqnqQBrWqoqolvDXqvhCFlvHVoohjDv3OXkrWhDV79d5j9eTmYug/IgAAAAAACiTDPq1b0qzaE3VJzaoG2ttcXExqVjVQ249fzPSYHcfjHPpLUsvqQdp+PM6+bbXaNHL5Tg1sWVnVS3pnrxaLRQkJCfZfiYmJOb8gAAAAAACQbYYNNOKuWJRutSnQy/GVkCAvD0Xf4JWT6IQUBXqZr+tvdnhF5cNNh+XmalK/ZhWzXcucOXPUoEED+6/27dtn/0IAAAAAAECOGX5R0NwUeeqSFv52TGtHNJfJZMr2cYMGDVK/fv3s26mpqTpy5EhelAgAAAAAAGTgQMO/qFmuLqYMC4BGJ6QoyCvzhTyDvDwUk2C5rr/FPsvj92MXFJuYoqZv/WDfn261adLafVrw61H99mKbTMc1m80ym/+Z+WGxWDLtBwAAAAAAcodhAw2zm4tql/XV5kMxuj+0lKSr619sPhSrPk0rZHpMeAV/bT4U4/AJ1l//jlb9Cv6SpC7hZdX8ujU2+izYqs7h5dStYbk8uhIAAAAAAJBThg00JOnp5pU06n+7FFbOT/WCffXxr8d0xZKmbg2CJUnPL9+pkr6eGvNADUnSU80qqsecLZr38xG1rlFCX+06rcioS5rcpY4kyb+YWf7FHNfYcHNxUZC3h6oEed3eiwMAAAAAADdk6EDjobpldCHRone/P6joyymqWcZHi566S0HeV18hibqY5LAWRoMKxfXeY+Ga9t0BvfPtAVUMLKq5vRsqpFT2vmYCAAAAAADuDCabzWbL7yIKGovFosjISIWFhTmsrQEAAAAAQF4ojM+hhv1sKwAAAAAAKLwINAAAAAAAgOEQaAAAAAAAAMMh0AAAAAAAAIZDoAEAAAAAAAyHQAMAAAAAABgOgQYAAAAAADAcAg0AAAAAAGA4BBoAAAAAAMBwCDQAAAAAAIDhEGgAAAAAAADDIdAAAAAAAACGQ6ABAAAAAAAMh0ADAAAAAAAYDoEGAAAAAAAwHAINAAAAAABgOAQaAAAAAADAcAg0AAAAAACA4RBoAAAAAABQCC1btkxt2rRRWFiYunXrpt27d2fZ/5NPPtH999+vOnXqqFWrVnrzzTeVkpJym6rNiEADAAAAAIBCZt26dZo8ebKGDh2q1atXq0aNGurfv79iY2Mz7f/VV19p2rRpGjZsmNatW6dJkyZp3bp1mj59+m2u/B8EGgAAAAAAFDILFy5U9+7d9eijj6pq1aqaOHGiPD099fnnn2faf8eOHapfv74eeughlStXTs2bN9eDDz5401kdeckt385cCKSnpys9PT2/ywAAAAAAFHDXnj0TExNlsVjs7WazWWaz2aGvxWLR3r17NWjQIHubi4uLmjZtqh07dmQ6fnh4uNasWaPdu3erTp06OnnypDZt2qROnTrlwdVkD4FGHtq3b19+lwAAAAAAKERat26tpKQk+/awYcM0fPhwhz5xcXFKT09XQECAQ3tAQICOHDmS6bgPPfSQ4uLi9Pjjj8tmsyktLU2PPfaYBg8enPsXkU0EGnmoVq1aGZIwAAAAAABym8Vi0b59+/Tjjz/K3d3d3p5bz6Rbt27VnDlz9Oqrr6pOnTo6ceKEJk2apNmzZ2vo0KG5co6cItDIQ66urnJ1dc3vMgAAAAAABdy1Z89ixYrdNMTw9/eXq6trhgVAY2NjFRgYmOkx7733nh5++GF169ZNkhQSEqIrV65o/PjxGjJkiFxcbv8SnSwKCgAAAABAIWI2mxUaGqqIiAh7m9VqVUREhMLDwzM9Jjk5OUNocS1EsdlseVdsFpihAQAAAABAIdOvXz+NGTNGtWvXVp06dbRo0SIlJSWpS5cukqTRo0erZMmSGjVqlKSra3MsXLhQtWrVsr9y8t5776l169b59mYCgQYAAAAAAIVMhw4ddOHCBc2cOVPR0dGqWbOm5s+fb3/l5MyZMw4zMoYMGSKTyaQZM2bo3LlzKl68uFq3bq2RI0fm1yXIZMuvuSEFmMViUWRkpMLCwlgUFAAAAACQ5wrjcyhraAAAAAAAAMMh0AAAAAAAAIZDoAEAAAAAAAyHQAMAAAAAABgOgQYAAAAAADAcAg0AAAAAAGA4BBoAAAAAAMBwCDQAAAAAAIDhEGgAAAAAAADDIdAAAAAAAACGQ6ABAAAAAAAMh0ADAAAAAAAYDoEGAAAAAAAwHAINAAAAAABgOAQaAAAAAADAcAg0AAAAAACA4RBoAAAAAAAAwyHQAAAAAAAAhkOgAQAAAAAADIdAAwAAAAAAGA6BBgAAAAAAMBwCDQAAAAAAYDgEGgAAAAAAwHAINAAAAAAAgOEQaAAAAAAAAMMh0AAAAAAAAIZDoAEAAAAAAAyHQAMAAAAAABgOgQYAAAAAADAcAg0AAAAAAGA4BBoAAAAAAMBwCDQAAAAAAIDhEGgAAAAAAADDIdAAAAAAAACGQ6ABAAAAAAAMh0ADAAAAAAAYDoEGAAAAAAAwHAINAAAAAABgOAQaAAAAAADAcAg0AAAAAACA4RBoAAAAAAAAwyHQAAAAAAAAhkOgAQAAAAAADIdAAwAAAAAAGI5bfhdwqxZHHNOcTUcUnZCimqV9NPHhUNUL9rth/7W7z2ja9wd0Ki5JlQKK6cX2NdS6RglJUmq6VVO/O6Cf/orWiQtX5O3ppuZVAzWmfQ2V9PG8TVcEAAAAAABuxtAzNL7adVpvfL1fz7arprXDm6tWaW/1+XirYhJSMu2/7fgFjfhsh3o0DNa6Ec11X2hJDVzypw6cvSxJSkpN196oeA1vW1Vfj2iuj3o30OGYRD296M/beVkAAAAAAOAmDB1ozP/1qB67K1jdGwarWklvTXokTEXMrlrx58lM+y/47ZhaVQ/SoFZVVLWEt0bdF6LQMr5aFHFMkuTj6a6lTzfWg3XKqEqQl+qX99drD4cqMuqSoi4m3cYrAwAAAAAAWTFsoGFJs2pP1CU1qxpob3NxMalZ1UBtP34x02N2HI9z6C9JLasHafvxuBue53Jymkwmycfzxm/nWCwWJSQk2H8lJibm7GIAAAAAAECOGDbQiLtiUbrVpkAvD4f2IC8PRd/glZPohBQFepmv62++4Ssqyanpemv9fj1ct4y8Pd1vWMucOXPUoEED+6/27dvn8GoAAAAAAEBOGH5R0LySmm7VsE+3y2aT3nikdpZ9Bw0apH79+v1zbGqqjhw5ktclAgAAAABQaBk20PAvapariynD7IrohBQFXTdr45ogLw/FJFiu62/JMMsjNd2qocu261Rckv474O4sZ2dIktlsltn8z8wPi8WSRW8AAAAAAHCrDPvKidnNRbXL+mrzoRh7m9Vq0+ZDsapfwS/TY8Ir+Dv0l6Rf/45W/Qr+9u1rYcax2EQte7qx/IuZrx8GAAAAAADkM8MGGpL0dPNK+u8fJ7Vy2ykdOn9ZL32xR1csaerWIFiS9PzynZqy/i97/6eaVdSmg9Ga9/MRHTqfoHe/P6jIqEt6sklFSVfDjCFLtysy6pJm9AhXus2m85eTdf5ysixp1vy4RAAAAAAAkAnDvnIiSQ/VLaMLiRa9+/1BRV9OUc0yPlr01F0K8r76CknUxSSZTCZ7/wYViuu9x8I17bsDeufbA6oYWFRzezdUSClvSdLZS8nasP+cJKnDzF8czvXfAXerSZWA23RlAAAAAAAgKyabzWbL7yIKGovFosjISIWFhTmsrQEAAAAAQF4ojM+hhn7lBAAAAAAAFE4EGgAAAAAAwHAINAAAAAAAgOEQaAAAAAAAAMMh0AAAAAAAAIZDoAEAAAAAAAyHQAMAAAAAABgOgQYAAAAAADAcAg0AAAAAAGA4BBoAAAAAAMBwCDQAAAAAAIDhEGgAAAAAAADDIdAAAAAAAACGQ6ABAAAAAAAMh0ADAAAAAAAYDoEGAAAAAAAwHAINAAAAAABgOAQaAAAAAADAcAg0AAAAAACA4RBoAAAAAAAAwyHQAAAAAAAAhkOgAQAAAAAADIdAAwAAAAAAGA6BBgAAAAAAMBwCDQAAAAAAYDhuuTVQkiVdX+06rZR0q1qHBKmcf9HcGhoAAAAAAMCBU4HG6JW7tPPkRX03spUkyZJmVecPftOBc5clSd4ebvp0wN2qXdY39yoFAAAAAAD4f069chJxJFYPhJayb3+5M0oHzl3WjB719N1zLRXk7aH3Nv6da0UCAAAAAIDctWzZMrVp00ZhYWHq1q2bdu/enWX/+Ph4TZw4Uc2bN1ft2rV1//33a9OmTbep2oycmqERfTnF4ZWS7/adU52yvupUr6wkqedd5TXn5yO5UyEAAAAAAMhV69at0+TJkzVx4kTVrVtXixYtUv/+/bV+/XoFBARk6G+xWNSvXz8FBATovffeU8mSJXX69Gn5+PjkQ/VXORVoFDW7KT45VZKUlm7VliOx6tu0on1/MQ83Xf7//QAAAAAA4M6ycOFCde/eXY8++qgkaeLEifrpp5/0+eefa+DAgRn6f/7557p06ZI+++wzubu7S5LKlSt3W2u+nlOBRmgZH/339xO6u3KANuw/p8SUNLWtWdK+/3jsFQV6eeRakUaVnp6u9PT0/C4DAAAAAFDAXXv2TExMlMVisbebzWaZzWaHvhaLRXv37tWgQYPsbS4uLmratKl27NiR6fg//PCD6tWrp9dee00bN25U8eLF9eCDD2rAgAFydXXNgyu6OacCjRfuD1GfBb/r4Vm/yiapQ+3SqhfsZ9//3d6zaljBP5dKNK59+/bldwkAAAAAgEKkdevWSkpKsm8PGzZMw4cPd+gTFxen9PT0DK+WBAQE6MiRzJePOHnypLZs2aKHHnpIc+fO1YkTJzRx4kSlpaVp2LBhuX8h2eBUoFGnnJ82Pt9K247HyaeIu+6u/M8fwqWkVPW6u4IaVy6ea0UaVa1atTIkYQAAAAAA5DaLxaJ9+/bpxx9/tL8SIinXnkltNpsCAgL0+uuvy9XVVbVr19a5c+f08ccfGyvQkKQALw/d968vnVzjW8RdTzWvdEtFFRSurq75NvUGAAAAAFB4XHv2LFas2E1DDH9/f7m6uio2NtahPTY2VoGBgZkeExQUJDc3N4dn3MqVKys6OloWiyVffpjv1Gdboy4m6Y9jFxza9p2O1/PLd2rop9v17d6zuVIcAAAAAADIXWazWaGhoYqIiLC3Wa1WRUREKDw8PNNj6tevrxMnTshqtdrbjh07pqCgoHx7M8GpQGPCmr2aseGgfTv6cop6ztui9XvP6vejFzRk6Tat33Mm14oEAAAAAAC5p1+/flqxYoVWr16tw4cPa8KECUpKSlKXLl0kSaNHj9a0adPs/Xv27KmLFy9q0qRJOnr0qH766SfNmTNHTzzxRH5dgnOvnOw6eVH9mv3zWsmq7aeUnJqu70a2VLB/UT258HfN/fmIHqhdOtcKBQAAAAAAuaNDhw66cOGCZs6cqejoaNWsWVPz58+3v3Jy5swZubj8MweidOnS+vjjjzV58mQ9/PDDKlmypPr06aMBAwbk1yU4F2hcTEpVgNc/U0o2/nVejSsHqEJAMUnS/aGl9M63B3KnQgAAAAAAkOt69eqlXr16ZbpvyZIlGdrCw8O1YsWKvC4r25x65SSgmFlRcVc/A3MpKVU7T1xUy2r/LBySbrUp3WrLnQoBAAAAAACu49QMjWZVA/XJ5mPy9nTTliOxstpsuv9fXzz5+/xllfb1zLUiAQAAAAAA/s2pQGPMAzV0NCZRk9btl7uri8Z1qKng4kUlSSlp6Vq7+4w61Subq4UCAAAAAABc41SgEeTtoc+HNFV8cqo83VxldvvnzRWbTVr29N0q48cMDQAAAAAAkDecCjSu8fF0z9Dm6e6qWmV8bmVYAAAAAACALDkdaFxOTtXHvx7Vj3+dV9TFqwuElvUrojY1Suqp5hXlnUnYAQAAAAAAkBucCjTOxSer20cROhl3RVWCvNSggr8k6Uh0omZsPKhVO07pf4OaqIQPr50AAAAAAIDc51Sg8dY3fyn6cooWPNlIrWuUcNj344HzGrpsu95a/5emd6+XGzUCAAAAAAA4cLl5l4w2HYzWU80rZggzJKl1SAn1bVpRPx2IvuXiAAAAAAAAMuNUoHHFkqZAL48b7g/y9tAVS5rTRQEAAAAAAGTFqUCjWglvrdl1WpY0a4Z9qelWrdl1WtVKeN9ycQAAAAAAwPjatGmjWbNm6fTp07k2plOBxuBWVbTz5EV1mv2bPt16QhGHYxVxOFbLth5Xp1m/adfJixpyT5VcKxIAAAAAABhXnz599P3336tdu3bq16+f1q5dK4vFcktjmmw2m82ZA//350lNWX9AsYkpMv1/m01SQDEPvdi+hro2KHdLhRmZxWJRZGSkwsLCZDab87scAAAAAEABZ5Tn0L1792r16tX6+uuvZbVa9eCDD+rRRx9VaGhojsdyOtCQpLR0q3ZHXVJUXJIkqax/EdUp6ys3V6cmfhQYRrmRAAAAAAAFg9GeQ1NTU/Xpp59q6tSpSktLU/Xq1dW7d289+uijMplMNx9ATn621X6wq4vql/dX/fL+Du1LthzXgl+P6sf/3HMrwwMAAAAAgAIkNTVV33//vVatWqXNmzerbt266tq1q86ePat3331XERERmjZtWrbGuqVA40YuXbHoeGxiXgwNAAAAAAAMZu/evVq1apW+/vprubi46JFHHtHYsWNVpco/62/ee++96tq1a7bHzJNAAwAAAAAA4JquXbuqadOmmjBhgtq1ayd3d/cMfcqVK6eOHTtme0wCDQAAAAAAkKc2bNigsmXLZtmnaNGimjx5crbHLNyrdwIAAAAAgDwXGxurXbt2ZWjftWuXIiMjnRqTQAMAAAAAAOSp1157TWfOnMnQfu7cOb322mtOjZntV05Cx6/P9qdTLOlWp4oBAAAAAAAFz+HDhxUaGpqhvWbNmjp06JBTY2Y70HigdmllM88AAAAAAACwM5vNiomJUXBwsEN7dHS03NycW94z20dN617XqRMAAAAAAIDCrVmzZpo+fbo++OADeXt7S5Li4+P17rvvqmnTpk6NyVdOAAAAAABAnhozZoyeeOIJtW7dWjVr1pQk/fXXXwoICNDbb7/t1JgEGgAAAAAAIE+VLFlSa9as0VdffaW//vpLnp6eevTRR9WxY0e5u7s7NSaBBgAAAAAAyHNFixZVjx49cm08Ag0AAAAAAHBbHDp0SKdPn1ZqaqpDe9u2bXM8FoEGAAAAAADIUydPntTQoUN18OBBmUwm2Ww2SZLp/z+nun///hyP6ZKrFQIAAAAAAFxn0qRJKleunDZv3ixPT0+tXbtWS5cuVe3atbVkyRKnxiTQAAAAAAAAeWrHjh0aMWKEihcvLhcXF5lMJjVs2FDPP/+83njjDafGdOqVk0pj18p0kz4ebq4q7eupu6sEaFDLyqoQUMyZUwEAAAAAAIOzWq0qVuxqLuDv76/z58+rcuXKKlu2rI4ePerUmE4FGiPaVNP3+87p7/OX1ap6CVUMKCpJOhabqE0HoxVSyltNqwTqWEyiVv55Sl/tPK3lg5qoVhkfp4oEAAAAAADGVa1aNR04cEDBwcGqW7eu5s+fL3d3d61YsULBwcFOjelUoFHSx1NxVyza+Pw9Kv//YcY1x2IS9djcLapawkvjOtTU0ZhEdfngN73z7V9a2O8up4oEAAAAAADGNWTIECUlJUmSRowYoUGDBumJJ56Qn5+f3n33XafGdCrQmPvzYfVuUiFDmCFJFQOLqXeTCvrwp8Pq3jBYlQKL6YnGFbQ44phTBQIAAAAAAGNr0aKF/fcVKlTQ+vXrdfHiRfn6+tq/dJJTTi0KeuZSstxcbnxCNxeTTl9Msm+X8y8iS7rVmVMBAAAAAAADS01NVa1atXTw4EGHdj8/P6fDDMnJGRrVS3pr6ZYT6hxeTkHeHg77zl9O1tKtx1W9pLe97cSFKxn65ZbFEcc0Z9MRRSekqGZpH018OFT1gv1u2H/t7jOa9v0BnYpLUqWAYnqxfQ21rlHCvt9ms+nd7w/qv3+cVHxSqhpW9Ncbj4SpUiCLmgIAAAAAkFPu7u4qXbq0rNbcnejg1AyNcR1q6lx8su5550eNXL5TMzYc1IwNBzVy+U61fucnnYtP0bgONSVJyanpWrntlJpUDsjVwiXpq12n9cbX+/Vsu2paO7y5apX2Vp+PtyomISXT/tuOX9CIz3aoR8NgrRvRXPeFltTAJX/qwNnL9j4fbTqihZuPadIjtfXF0GYq4u6mPgu2Kjk1PdfrBwAAAACgMBg8eLCmT5+uixcv5tqYJpvNZnPmwD1RlzRjw0H9dihWyWlXH/Y93FzUvGqgnmtXXbXL+uZakTfSafZvqlvOV691qi1JslptavLWRj3ZtKKeuadqhv5DP92uJEu6FvRtZG97ZPZvqlXGR292DpPNZtNdb27UgBaVNLBlFUlSfHKqGr6xQVO71dXDdctkqy6LxaLIyEiFhYXJbDbnwpUCAAAAAHBjd/pz6COPPKLjx48rLS1NZcqUUdGijmtyrl69OsdjOvXKiSTVLuur+U82ktVqU0zi1RkRgcU85JLF2hq5yZJm1Z6oS3rmnir2NhcXk5pVDdT24xczPWbH8Tj1b1HZoa1l9SB9t/esJOnkhSRFX05Rs6qB9v0+nu6qF+yn7cfjbhhoWCwWWSwW+3ZqaqqzlwUAAAAAQIHTrl27XB/T6UDjGhcXk0p4e+ZGLTkSd8WidKtNgV6Oa3MEeXnocHRipsdEJ6Qo0Mt8XX+z/RWV6IRk+xjXjxl9g9dYJGnOnDmaNWuWfdvf31+zZ8/O/sUAAAAAAFCADRs2LNfHdDrQuHQlVWt2RenEhSu6lJSq619cMZmkt7vWvdX6DGHQoEHq16+ffTs1NVVHjhzJx4oAAAAAACjYnAo0Nh2M1jNLt+lKarq8PNzkW8Q9Q59b+PJKtvgXNcvVxZRhAdDohJQMMyyuCfLyUEyC5br+FvssjyAvT/sYJXw8/9UnRbVK+9ywFrPZ7PCO0r9fPwEAAAAAoLCrUaNGlp9o3b9/f47HdCrQmLR2n4K8PfRR7waqUerGD/p5yezmotplfbX5UIzuDy0l6eqioJsPxapP0wqZHhNewV+bD8Wof/NK9rZf/45W/Qr+kqTg4kUU5O2hzYdiFVrm6qKml5NTtfPkRfW6O/MxAQAAAABA1v69TIMkpaWlaf/+/Vq9erWGDx/u1JhOBRrHYq9oXPsa+RZmXPN080oa9b9dCivnp3rBvvr412O6YklTtwbBkqTnl+9USV9PjXmghiTpqWYV1WPOFs37+Yha1yihr3adVmTUJU3uUkeSZDKZ9FSzSnr/h79VMbCYgosX0bTvDqqkj4fuq1Uy364TAAAAAAAjy2xR0AceeEBVq1bVunXr1K1btxyP6VSgUSmgmBIt6c4cmqseqltGFxItevf7g4q+nKKaZXy06Km7FOR99RWSqItJDlNaGlQorvceC9e07w7onW8PqGJgUc3t3VAhpbztfQa3qqwkS5rGropUfHKqGlX016J+d8nT3fW2Xx8AAAAAAAVZvXr1NH78eKeONdls1y/neXPf7T2r8V/u1f8GN1Fw8aI3P6CQudO//wsAAAAAKFiM+ByanJysadOm6eeff9a3336b4+OdmqGx+XCsihczq930TWpRLVClfYvI1SXj4h4THg51ZngAAAAAAFCANGrUyOENCpvNpsTERHl6euqdd95xakynAo1FEcfsv9/41/lM+5hEoAEAAAAAAKSxY8c6BBomk0nFixdX3bp15evr69SYTgUaRyd3dOpkAAAAAACg8OnSpUuuj+mS6yMCAAAAAAD8y+eff65vvvkmQ/s333yj1atXOzUmgQYAAAAAAMhTc+fOlb+/f4b2gIAAffTRR06Nma1XTiqNXSsXk0n7X3tAZjcXVRq7VhmXAHVkMpl0+M0OThUFAAAAAAAKjtOnT6tcuXIZ2suUKaMzZ844NWa2Ao0RbarJZJLc/v9LJte2AQAAAAAAbiYgIEAHDhzIEGr89ddf8vPzc2rMbAUaI++tnuU2AAAAAADAjXTs2FGTJk1SsWLF1KhRI0nS77//rjfffFMdOzr34RGnvnICAAAAAACQXc8++6yioqLUt29fubldjSKsVqs6deqkkSNHOjWm04FGutWmnw9G68SFK7qUlCqbzXG/ySSNaFvN2eEBAAAAAEABYTabNWPGDB07dkz79++Xp6enqlevrrJlyzo9plOBxu5TFzVk6XaduZQk2w36mESgAQAAAAAA/lGxYkVVrFgxV8ZyKtB45Ys9Sk5N19zeDdWoUnH5FnHPlWIAAAAAAEDBM3z4cIWFhWngwIEO7fPmzVNkZKRmzpyZ4zFdnClk/9nLGtyqitrVKkmYAQAAAAAAsvTHH3+oVatWGdpbtmypP//806kxnQo0Svt6ynbDl00AAAAAAAD+ceXKFbm7Z5wQ4ebmpoSEBKfGdCrQGNyqij77/aQuJ6c6dVIAAAAAAFB4VK9eXevWrcvQvm7dOlWtWtWpMZ1aQyMxJU1FPVx1zzs/6aG6ZVTa11OuLqYM/Z5uUdmpogAAAAAAQMHxzDPPaPjw4Tp58qTuvvtuSVJERIS+/vprp9bPkJwMNCat22///aKIY5n2MYlAAwAAAAAASG3atNHs2bP10Ucf6dtvv5WHh4dq1KihRYsWydfX16kxTTabLceLYZyKu5KtfuX8i+a4oILAYrEoMjJSYWFhMpvN+V0OAAAAAKCAM9pzaEJCgr7++mutXLlSe/fu1f79+29+0HWcmqFRWIMKAAAAAADgvD/++EMrV67Ud999pxIlSujee+/V+PHjnRrLqUADAAAAAAAgO6Kjo7V69WqtXLlSCQkJat++vSwWi2bPnu30gqBSNgON5lN+kIvJpI2jWsnd1UXNp/wgU8Y1QB2YZNLPo1s7XRgAAAAAADC2wYMH648//tA999yjcePGqUWLFnJ1ddVnn312y2NnK9BoXClAJpPk8v8pxrVtAAAAAACAG/n555/Vu3dv9ezZUxUrVszVsbMVaEzrXjfLbQAAAAAAgOt9+umnWrlypbp06aIqVaqoU6dO6tChQ66M7ZIrowAAAAAAAFynXr16euONN/Trr7+qR48eWrt2rVq2bCmr1arffvtNCQkJTo/t1Gdbr0lNt+pwdIIuJ6fJas04TOPKAU4XZmRG+1wOAAAAAMDYjPQceuTIEa1cuVJr1qxRfHy8mjZtqo8++ijH4zj1lROr1aYp3/6lpRHHlZSafuMiJ3d0ZngAAAAAAFBAVa5cWaNHj9aoUaP0448/auXKlU6N41SgMfvHQ5r78xE9fld5NapYXCNX7NSLD9SQTxF3LYk4LpNJGtu+plMFAQAAAACAgs/V1VXt2rVTu3btnDreqTU0Vm4/pY5hpTWpc5haVQ+SJIWV9VXPu8rri6HNZDJJmw/HOFUQAAAAAADAzTgVaJy5lKymVQIlSWa3q0OkpFnt24/UK6vVO6JyqUQAAAAAAABHTgUa/kXddcWSJkkq5uEmLw83nbhwxaHPpaTUW68OAAAAAAAgE06toRFaxle7Tl2ybzepHKAFvx1VaBkfWW3SJ5uPqWZpn1wrEgAAAAAA4N+cmqHxWKNgWdLSlZJ29QsnL9wfovikVHWfE6EecyOUkJKmlzqyKCgAAAAAAMgbTs3QuC+0lO4LLWXfrlbSW5tGt9aWw7FydTGpQQV/+RW9s797CwAAAAAAjCvHgUZyarre+faAmlQOULtaJe3tPp7uDiEHAAAAAABAXsnxKyee7q76dOsJxSSk5EU9AAAAAAAAN+XUGhphZX114Nzl3K4FAAAAAADcJsuWLVObNm0UFhambt26affu3dk6bu3atQoJCdEzzzyTxxVmzalAY/xDtfTVrjP67PcTSku35nZNAAAAAAAgD61bt06TJ0/W0KFDtXr1atWoUUP9+/dXbGxslsedOnVKU6ZMUcOGDW9TpTdmstlstux03HokVlVLeCnAy0P3v/uz4q5YFJOQIrObi0r5eMrT3TXDMeufa5nrBRuBxWJRZGSkwsLCZDazOCoAAAAAIG/l9Dm0W7duCgsL0/jx4yVJVqtVrVq1Uu/evTVw4MBMj0lPT9cTTzyhRx99VNu2bVN8fLw++OCDXL2OnMj2oqA9523Ruz3qqVO9svIr6i7/Yu6qHFQsL2szvPT0dKWnp+d3GQAAAACAAu7as2diYqIsFou93Ww2Zwg4LBaL9u7dq0GDBtnbXFxc1LRpU+3YseOG55g9e7YCAgLUrVs3bdu2LZevIOeyHWj8exrH8kFN8qCUgmffvn35XQIAAAAAoBBp3bq1kpKS7NvDhg3T8OHDHfrExcUpPT1dAQEBDu0BAQE6cuRIpuP++eefWrlypb744otcr9lZOf5sK7KvVq1avHICAAAAAMhzFotF+/bt048//ih3d3d7e248kyYkJGj06NF6/fXXVbx48VseL7cQaOQhV1dXubpmXFsEAAAAAIDcdO3Zs1ixYjcNMfz9/eXq6pphAdDY2FgFBgZm6H/y5ElFRUVpyJAh9jar9eoHQmrVqqX169erfPnyt3oJOZajQGPk8p0auXxntvqaTCYdfrODMzUBAAAAAIA8YjabFRoaqoiICLVr107S1YAiIiJCvXr1ytC/cuXK+uqrrxzaZsyYocTERL300ksqVarUban7ejkKNJpVDVTlQBYCBQAAAADAyPr166cxY8aodu3aqlOnjhYtWqSkpCR16dJFkjR69GiVLFlSo0aNkoeHh6pXr+5wvI+PjyRlaL+dchRodG1QTp3qlc2rWgAAAAAAwG3QoUMHXbhwQTNnzlR0dLRq1qyp+fPn2185OXPmjFxcXPK5yqyxhgYAAAAAAIVQr169Mn3FRJKWLFmS5bFvvfVWXpSUI3d23AIAAAAAAJAJAg0AAAAAAGA42X7l5OjkjnlZBwAAAAAAQLYxQwMAAAAAABgOgQYAAAAAADAcAg0AAAAAAGA4BBoAAAAAAMBwCDQAAAAAAIDhEGgAAAAAAADDIdAAAAAAAACGQ6ABAAAAAAAMh0ADAAAAAAAYDoEGAAAAAAAwHAINAAAAAABgOAQaAAAAAADAcAg0AAAAAACA4RBoAAAAAAAAwyHQAAAAAAAAhkOgAQAAAAAADIdAAwAAAAAAGA6BBgAAAAAAMBwCDQAAAAAAYDgEGgAAAAAAwHAINAAAAAAAgOEQaAAAAAAAAMMh0AAAAAAAAIZDoAEAAAAAAAzHLb8LcNbFKxa9umavNu4/L5NJal+7lF59KFTFPG58Scmp6Zq0dr++2n1aljSrWlYL0uuP1FaQt4ckad/peH246bD+PHZBFxItKudfRE80rqCnmle6XZcFAAAAAACywbAzNJ79bKcOnkvQkv53aUHfRvr96AWNXRWZ5TGvf71PG/ef0weP19fygU107nKyBi/dZt+/J+qSAoqZ9W6Pevp+ZCsNa1NVb3/7lxZtPpbHVwMAAAAAAHLCkDM0Dp2/rE0Ho7VmWDPVKecnSZrwcKj6ffKHXupYUyV9PDMcE5+cqhV/ntR7j4WradVASdI7Xeuq3fRN2n4iTvXL+6t7o2CHY8oHFNX24xe1fs9ZPdm0Yl5fFgAAAAAAyCZDztDYfvyifDzd7GGGJDWvGigXk0k7TlzM9Jg9py4pNd2mZv8fZkhS1RJeKutXRNuPx93wXJeTU+VX1D3LeiwWixISEuy/EhMTc3Q9AAAAAAAgZwwZaEQnpCjQy8Ohzc3VRX5F3BWdkHLDY8yuLvIt4hhOBHqZb3jMtuMX9PXuM+p5V/ks65kzZ44aNGhg/9W+ffscXA0AAAAAAMipO+qVk7e++UsfbTqcZZ8Nz7e6LbUcOHtZAxZv07Ntq6ll9aAs+w4aNEj9+vWzb6empurIkSN5XSIAAAAAAIXWHRVoDGhRSV0blMuyT/niRRXk5aGY62ZVpKVbdTEpVUHXzdy4JsjLQ5Z0qy4lpTrM0ohJsGQ45u9zl/XE/C3qeVewhretdtO6zWazzGazfdtisdz0GAAAAAAA4Lw7KtAI8PJQwA0CiX+rX8FP8clpijx1SWHlfCVJmw/HymqzKby8X6bH1C7nK3dXkzYfilH7sNKSpMPRCYq6mKT6Ffzt/Q6eu6zH523Ro/XL6YX7a9z6RQEAAAAAgFxnyDU0qpbwVqvqQXpx1W7tPHlRfx67oFfX7NVDdcrYv3By9lKy2kz7STtPXpQk+Xi6q3vDYL2xdr82H45R5KlLeuF/u1S/vJ/ql78aaBw4e1k9525Ri2pB6t+iks5fTtb5y8mKvcEaGwAAAAAAIH/cUTM0cuK9x+pp/Jd79cS8LXIxmfRA7VKa8HCofX9qulVHohOVZEm3t73yYC25mPZryNLtsqRZ1bJ6oF5/pLZ9/7rIM4pNtGj1jiit3hFlby/rV0S/vdjm9lwYAAAAAAC4KZPNZrPldxEFjcViUWRkpMLCwhzW1gAAAAAAIC8UxudQQ75yAgAAAAAACjcCDQAAAAAAYDgEGgAAAAAAwHAINAAAAAAAgOEQaAAAAAAAAMMh0AAAAAAAAIZDoAEAAAAAAAyHQAMAAAAAABgOgQYAAAAAADAcAg0AAAAAAGA4BBoAAAAAAMBwCDQAAAAAAIDhEGgAAAAAAADDIdAAAAAAAACGQ6ABAAAAAAAMh0ADAAAAAAAYDoEGAAAAAAAwHAINAAAAAABgOAQaAAAAAADAcAg0AAAAAACA4RBoAAAAAAAAwyHQAAAAAAAAhkOgAQAAAAAADIdAAwAAAAAAGA6BBgAAAAAAMBwCDQAAAAAAYDgEGgAAAAAAwHAINAAAAAAAgOEQaAAAAAAAAMMh0AAAAAAAAIZDoAEAAAAAAAyHQAMAAAAAABgOgQYAAAAAADAcAg0AAAAAAGA4BBoAAAAAAMBwCDQAAAAAAIDhEGgAAAAAAADDIdAAAAAAAACGQ6ABAAAAAAAMh0ADAAAAAAAYDoEGAAAAAAAwHAINAAAAAABgOAQaAAAAAADAcAg0AAAAAACA4RBoAAAAAABQCC1btkxt2rRRWFiYunXrpt27d9+w74oVK/T444+rUaNGatSokfr27Ztl/9uBQAMAAAAAgEJm3bp1mjx5soYOHarVq1erRo0a6t+/v2JjYzPtv3XrVnXs2FGLFy/WZ599ptKlS+upp57SuXPnbnPl/zDZbDZbvp29gLJYLIqMjFStWrVkNpvzuxwAAAAAQAFnsVi0b98+Va5cWe7u7vZ2s9mc6XNpt27dFBYWpvHjx0uSrFarWrVqpd69e2vgwIE3PV96eroaNWqk8ePH65FHHsm168gJt3w5ayGxb9++/C4BAAAAAFCItG7dWklJSfbtYcOGafjw4Q59LBaL9u7dq0GDBtnbXFxc1LRpU+3YsSNb50lKSlJaWpp8fX1zp3AnEGjkIWZoAAAAAABuh2szNH788ccMMzSuFxcXp/T0dAUEBDi0BwQE6MiRI9k639SpU1WiRAk1bdr01gq/BQQaecjV1VWurq75XQYAAAAAoIC79uxZrFixPP/B+ty5c7Vu3TotXrxYHh4eeXqurBBoAAAAAABQiPj7+8vV1TXDAqCxsbEKDAzM8tiPP/5Yc+fO1cKFC1WjRo28LPOm+MoJAAAAAACFiNlsVmhoqCIiIuxtVqtVERERCg8Pv+Fx8+bN0wcffKD58+crLCzsdpSaJWZoAAAAAABQyPTr109jxoxR7dq1VadOHS1atEhJSUnq0qWLJGn06NEqWbKkRo0aJenqayYzZ87UtGnTVLZsWUVHR0uSihYtqmLFiuXLNRBoAAAAAABQyHTo0EEXLlzQzJkzFR0drZo1a2r+/Pn2V07OnDkjF5d/Xur47LPPlJqaqhEjRjiMk9lXVG4Xk81ms+XLmQswi8WiyMhIhYWF8ZUTAAAAAECeK4zPoayhAQAAAAAADIdAAwAAAAAAGA6BBgAAAAAAMBwCDQAAAAAAYDgEGgAAAAAAwHAINAAAAAAAgOEQaAAAAAAAAMMh0AAAAAAAAIZDoAEAAAAAAAyHQAMAAAAAABgOgQYAAAAAADAcAg0AAAAAAGA4BBoAAAAAAMBwCDQAAAAAAIDhEGgAAAAAAADDIdAAAAAAAACGQ6ABAAAAAAAMh0ADAAAAAAAYjlt+F+Csi1csenXNXm3cf14mk9S+dim9+lCoinnc+JKSU9M1ae1+fbX7tCxpVrWsFqTXH6mtIG+PDH3jEi1q/94vOhufrF2v3iffIu55eTkAAAAAACAHDDtD49nPdurguQQt6X+XFvRtpN+PXtDYVZFZHvP61/u0cf85ffB4fS0f2ETnLidr8NJtmfYd/flu1SjtnRelAwAAAACAW2TIQOPQ+cvadDBaUx4NU3h5fzWqWFwTHg7VV7tP61x8cqbHxCenasWfJ/Xyg7XUtGqgwsr56p2udbXteJy2n4hz6Ltky3HFJ6VqYIvKt+NyAAAAAABADhky0Nh+/KJ8PN1Up5yfva151UC5mEzaceJipsfsOXVJqek2NasaaG+rWsJLZf2KaPvxfwKNv89d1syNf2t6j3oymUzZqsdisSghIcH+KzEx0anrAgAAAAAA2WPIQCM6IUWBXo7rXri5usiviLuiE1JueIzZ1SXDWhiBXmb7MSlp6Rr+3x0a16GGyvoVyXY9c+bMUYMGDey/2rdvn8MrAgAAAAAAOXFHLQr61jd/6aNNh7Pss+H5Vnl2/rfXH1DVEl7qHF4uR8cNGjRI/fr1s2+npqbqyJEjuV0eAAAAAAD4f3dUoDGgRSV1bZB1mFC+eFEFeXko5rqZGGnpVl1MSlWQV8YvlkhSkJeHLOlWXUpKdZilEZNgsR+z+XCsDpyNV5Vx6yRJNptNklT/9e81tHVVPX9v9UzHNpvNMpvN9m2LxXKTKwUAAAAAALfijgo0Arw8FHCDQOLf6lfwU3xymiJPXVJYOV9JV8MIq82m8PJ+mR5Tu5yv3F1N2nwoRu3DSkuSDkcnKOpikupX8JckfdSrvpJTrfZjdp26qNErd2vFoCaqEFD0Fq8OAAAAAADkljsq0MiuqiW81ap6kF5ctVuTOocpLd2qV9fs1UN1yqikj6ck6eylZD0+f4umd6+nesF+8vF0V/eGwXpj7X75FnWXt4e7Xl2zR/XL+6l++auBRoWAYg7nuZBo+f/zeWVYewMAAAAAAOQfQwYakvTeY/U0/su9emLeFrmYTHqgdilNeDjUvj813aoj0YlKsqTb2155sJZcTPs1ZOl2WdKsalk9UK8/Ujs/ygcAAAAAALfAZLu2UARyjcViUWRkpMLCwhzW1gAAAAAAIC8UxudQQ362FQAAAAAAFG4EGgAAAAAAwHAINAAAAAAAgOEQaAAAAAAAAMMh0AAAAAAAAIZDoAEAAAAAAAyHQAMAAAAAABgOgQYAAAAAADAcAg0AAAAAAGA4BBoAAAAAAMBwCDQAAAAAAIDhEGgAAAAAAADDIdAAAAAAAACGQ6ABAAAAAAAMh0ADAAAAAAAYDoEGAAAAAAAwHAINAAAAAABgOAQaAAAAAADAcAg0AAAAAACA4RBoAAAAAAAAwyHQAAAAAAAAhkOgAQAAAAAADIdAAwAAAAAAGA6BBgAAAAAAMBwCDQAAAAAAYDgEGgAAAAAAwHAINAAAAAAAgOEQaAAAAAAAAMMh0AAAAAAAAIZDoAEAAAAAAAyHQAMAAAAAABgOgQYAAAAAADAcAg0AAAAAAGA4BBoAAAAAAMBwCDQAAAAAAIDhEGgAAAAAAADDIdAAAAAAAACGQ6ABAAAAAAAMh0ADAAAAAAAYDoEGAAAAAAAwHAINAAAAAABgOAQaAAAAAADAcAg0AAAAAACA4RBoAAAAAAAAwyHQAAAAAAAAhkOgAQAAAAAADIdAAwAAAAAAGA6BBgAAAAAAMBwCDQAAAAAAYDgEGgAAAAAAwHAINAAAAAAAgOEQaAAAAAAAAMMh0AAAAAAAoBBatmyZ2rRpo7CwMHXr1k27d+/Osv8333yjBx54QGFhYXrooYe0adOm21Rp5gg0AAAAAAAoZNatW6fJkydr6NChWr16tWrUqKH+/fsrNjY20/7bt2/XqFGj1LVrV33xxRdq27athg4dqoMHD97myv9BoAEAAAAAQCGzcOFCde/eXY8++qiqVq2qiRMnytPTU59//nmm/RcvXqwWLVro6aefVpUqVfTcc8+pVq1aWrp06W2u/B9u+XbmAsxqtUqSkpKSlJ6ens/VAAAAAAAKOovFIkm6fPmyPDw87O1ms1lmszlD371792rQoEH2NhcXFzVt2lQ7duzIdPydO3eqb9++Dm3NmzfXhg0bcukKco5AIw+kpaVJkg4dOpTPlQAAAAAACpOOHTsqLi7Ovj1s2DANHz7coU9cXJzS09MVEBDg0B4QEKAjR45kOm5MTIwCAwMz9I+JicmlynOOQCMPeHp6KiQkRG5ubnJx4a0eAAAAAEDeslqtSkpK0vr16+Xm9s+j/vWzMwoSAo084ObmJi8vr/wuAwAAAABQiHh6emarn7+/v1xdXTMsABobG5thFsY1gYGBGWZjZNX/dmD6AAAAAAAAhYjZbFZoaKgiIiLsbVarVREREQoPD8/0mHr16mnLli0ObZs3b1a9evXystQsEWgAAAAAAFDI9OvXTytWrNDq1at1+PBhTZgwQUlJSerSpYskafTo0Zo2bZq9f58+ffTLL79owYIFOnz4sN5//33t2bNHvXr1yq9L4JUTAAAAAAAKmw4dOujChQuaOXOmoqOjVbNmTc2fP9/+CsmZM2cc1oSsX7++pk6dqhkzZmj69OmqWLGiZs+ererVq+fXJchks9ls+XZ2AAAAAAAAJ/DKCQAAAAAAMBwCDQAAAAAAYDgEGgAAAAAAwHAINAAAAAAAgOEQaAA5cPHiRY0aNUr169dXw4YNNW7cOCUmJmZ5TEpKiiZOnKjGjRsrPDxcw4cPV0xMTKZ94+Li1LJlS4WEhCg+Pj4vLgEFXF7co3/99Zeef/55tWrVSnXq1FH79u21aNGivL4UFBDLli1TmzZtFBYWpm7dumn37t1Z9v/mm2/0wAMPKCwsTA899JA2bdrksN9ms+m9995T8+bNVadOHfXt21fHjh3LwytAQZeb92hqaqreeecdPfTQQ6pXr56aN2+u0aNH69y5c3l9GSjAcvu/o/82fvx4hYSE6JNPPsnlqoHbg0ADyIH//Oc/OnTokBYuXKiPPvpIf/75p8aPH5/lMW+++aZ+/PFHzZgxQ0uWLNH58+c1bNiwTPu+9NJLCgkJyYvSUUjkxT26Z88eFS9eXO+8847Wrl2rwYMHa/r06Vq6dGleXw4Mbt26dZo8ebKGDh2q1atXq0aNGurfv79iY2Mz7b99+3aNGjVKXbt21RdffKG2bdtq6NChOnjwoL3PvHnztGTJEk2YMEErVqxQkSJF1L9/f6WkpNyuy0IBktv3aHJysvbt26chQ4Zo1apVmjVrlo4ePaohQ4bczstCAZIX/x295vvvv9euXbtUokSJvL4MIO/YAGTLoUOHbNWrV7ft3r3b3rZp0yZbSEiI7ezZs5keEx8fbwsNDbV98803GcbZsWOHQ99ly5bZevXqZdu8ebOtevXqtkuXLuXJdaDgyut79N8mTJhg6927d67VjoKpa9eutokTJ9q309PTbc2bN7fNmTMn0/7PPvusbeDAgQ5t3bp1s73yyis2m81ms1qttmbNmtnmz59v3x8fH2+rXbu27euvv86DK0BBl9v3aGZ27dplq169ui0qKip3ikahklf36NmzZ20tWrSwHTx40Na6dWvbwoULc7124HZghgaQTTt27JCPj4/CwsLsbU2bNpWLi8sNp/7t2bNHqampatq0qb2tSpUqKlOmjHbu3GlvO3TokD744ANNmTJFLi78zxLOyct79HqXL1+Wn59fbpWOAshisWjv3r0O95aLi4uaNm2qHTt2ZHrMzp071aRJE4e25s2b2+/FU6dOKTo62mFMb29v1a1b94ZjAjeSF/doZhISEmQymeTj45MrdaPwyKt71Gq16oUXXlD//v1VrVq1PKkduF14cgKyKSYmRsWLF3doc3Nzk6+vr6Kjo294jLu7e4Z/xAQEBNiPsVgsev755/XCCy+oTJkyeVM8CoW8ukevt337dn3zzTfq3r177hSOAikuLk7p6ekKCAhwaA8ICLjhOkIxMTEKDAy8Yf9r92ROxgRuJC/u0eulpKRo6tSp6tixo7y8vHKncBQaeXWPzps3T25uburTp0/uFw3cZm75XQCQ36ZOnap58+Zl2WfdunV5dv5p06apSpUq6tSpU56dA8aW3/fovx08eFDPPPOMhg4dqubNm9+WcwKAEaWmpurZZ5+VzWbTxIkT87scQNLVmZmLFy/WqlWrZDKZ8rsc4JYRaKDQe+qpp9S5c+cs+wQHByswMFAXLlxwaE9LS9OlS5cUFBSU6XGBgYFKTU1VfHy8w0/AY2Nj7cds2bJFBw8e1Lfffivp6gr+knT33Xdr8ODBGjFihNPXhoIhv+/Raw4dOqS+ffuqR48eeuaZZ5y8GhQW/v7+cnV1zbBwXWxsbIafHl4TGBiY4aeO/+5/7Z6MjY11WMQuNjZWNWrUyM3yUQjkxT16TWpqqp577jmdPn1aixYtYnYGnJIX9+iff/6p2NhYtW7d2r4/PT1dU6ZM0eLFi/XDDz/k8lUAeYtAA4Ve8eLFM0zTz0x4eLji4+O1Z88e1a5dW9LVMMJqtapOnTqZHlO7dm25u7srIiJC999/vyTpyJEjOn36tOrVqydJev/995WcnGw/JjIyUuPGjdOyZctUvnz5W7w6FAT5fY9K0t9//60nn3xSjzzyiEaOHHnrF4UCz2w2KzQ0VBEREWrXrp2kq+9tR0REqFevXpkeU69ePW3ZskV9+/a1t23evNl+L5YrV05BQUGKiIhQzZo1JV1dn2DXrl3q2bNnnl4PCp68uEelf8KM48ePa/HixfL398/Ly0ABlhf3aKdOnRzW5JCk/v37q1OnTurSpUueXAeQl1hDA8imKlWqqEWLFnrllVe0e/dubdu2Ta+//ro6duyokiVLSpLOnTunBx54wL4Ao7e3tx599FG99dZb2rJli/bs2aNx48YpPDzc/n8s5cuXV/Xq1e2/ypUrZz/f9e9MAlnJq3v04MGD6tOnj5o1a6Z+/fopOjpa0dHRGWaDANfr16+fVqxYodWrV+vw4cOaMGGCkpKS7P9oHj16tKZNm2bv36dPH/3yyy9asGCBDh8+rPfff1979uyx/8PdZDKpT58++vDDD7Vx40YdOHBAo0ePVokSJez/2AdyIrfv0dTUVI0YMUJ79uzR1KlTlZ6ebv9vpsViyZdrhLHl9j3q7+/v8O/O6tWry93dXYGBgapcuXK+XCNwK5ihAeTA1KlT9frrr+vJJ5+Ui4uL7rvvPr388sv2/ampqTp69KiSkpLsbePGjZOLi4tGjBghi8Wi5s2b69VXX82P8lEI5MU9+u233+rChQtas2aN1qxZY28vW7YsU1ORpQ4dOujChQuaOXOmoqOjVbNmTc2fP98+9fnMmTMOX3aqX7++pk6dqhkzZmj69OmqWLGiZs+ererVq9v7DBgwQElJSRo/frzi4+PVoEEDzZ8/Xx4eHrf9+mB8uX2Pnjt3zv7fxevXxlq8eLEaN258m64MBUVe/HcUKEhMtmsv7AMAAAAAABgEr5wAAAAAAADDIdAAAAAAAACGQ6ABAAAAAAAMh0ADAAAAAAAYDoEGAAAAAAAwHAINAAAAAABgOAQaAAAAAADAcAg0AAAAAACA4RBoAAAKta1btyokJETr16/P71KyJSYmRiNGjFDjxo0VEhKiTz75JN9qufZnt3Xr1hwfe+rUKYWEhGjVqlV5UNnt0aZNGw0aNCi/y8iRxMRENWnSRGvWrMnvUnJs6tSp6tatW36XAQC4g7jldwEAgIJv1apVGjt2rMxmszZs2KCSJUs67O/du7fi4uL09ddf51OFxjF58mT98ssvGjZsmAIDA1W7du0MfV588UWtXr36pmN17txZb731Vl6Uecdq06aNoqKibtpv8uTJ6tKly22o6PZavHixihUrpo4dO9rbzp8/r8WLF2vXrl3as2ePrly5osWLF6tx48ZOn+fIkSP67LPPtHv3bu3du1cWi0UbN25UuXLlMu2/ceNGzZo1S4cOHVJAQIC6dOmiZ555Rm5u//xT9cknn9SiRYu0ceNGtW3b1unaAAAFB4EGAOC2sVgsmjt3rl555ZX8LsWwtmzZorZt26p///437NOjRw81adLEvn3q1CnNnDlTPXr0UIMGDezt5cuXv6VaGjVqpN27d8vd3T3Hx5YtW1a7d+92eGC9HcaNG6fExET79s8//6yvv/5aY8eOlb+/v729fv36t7Wu2yE1NVWLFy9W37595erqam8/evSo5s2bp4oVKyokJEQ7duy45XPt3LlTS5YsUdWqVVWlShXt37//hn03bdqkoUOH6q677tIrr7yigwcP6sMPP1RsbKwmTpxo7xcUFKS2bdtqwYIFBBoAAEkEGgCA26hmzZpasWKFBg4cmGGWRkF35coVFS1a9JbHiY2NlY+PT5Z9wsPDFR4ebt+OjIzUzJkzVa9ePXXq1CnXanRxcZGHh0e2+/+byWRy+thb0a5dO4ftmJgYff3112rXrt0NZw8UFD/99JMuXLig9u3bO7SHhoZq69at8vPz0/r163Ml0GjTpo3++OMPeXl56eOPP84y0Hj77bcVEhKiBQsW2AOuYsWKac6cOerTp4+qVKli79u+fXs9++yzOnnypIKDg2+5TgCAsbGGBgDgthk0aJCsVqvmzZuXZb+s1lcICQnR+++/b99+//33FRISoqNHj+o///mPGjRooLvvvlszZsyQzWbTmTNnNGTIENWvX1/NmjXTggULMj2n1WrV9OnT1axZM9WrV0+DBw/WmTNnMvTbtWuX+vfvrwYNGqhu3brq1auXtm3b5tDnWk2HDh3SqFGj1KhRIz3++ONZXvPJkyc1YsQI3XXXXapbt666d++un376yb5/1apVCgkJkc1m07JlyxQSEqKQkJAsx8zKtfF+//13TZgwQU2aNFGrVq0kSVFRUZowYYLuv/9+1alTR40bN9aIESN06tQphzEyW0Ojd+/eevDBB3Xo0CH17t1bdevWVYsWLTL8nWf2d/ziiy8qPDxc586d0zPPPKPw8HDdfffdmjJlitLT0x2Oj4uL0wsvvKD69eurYcOGGjNmjP76669cWZcjLS1Ns2fPVrt27VS7dm21adNG06dPl8Viuemxq1evVq1atTRlyhR7W07umePHj+vFF19Uw4YN1aBBA40dO1ZJSUkOfX/77Tf17NlTDRs2VHh4uO6//35Nnz79prVt2LBBZcuWzTAzx8vLS35+fjc9/povv/xSXbp0UZ06dXTXXXdp5MiRGf634ufnJy8vr5uOdejQIR06dEjdu3d3mK3z+OOPy2az6dtvv3Xo37RpU0lXX1EBAIBAAwBw25QrV06dOnXSihUrdO7cuVwde+TIkbLZbBo1apTq1q2rDz/8UIsWLVK/fv1UsmRJ/ec//1H58uU1ZcoU/fHHHxmO//DDD/XTTz9pwIAB6t27tzZv3qy+ffsqOTnZ3iciIkJPPPGEEhMTNWzYMI0cOVLx8fF68skntXv37gxjPvvss0pKStLIkSOzXMwwJiZGjz32mH799Vf17NlTI0eOVEpKioYMGaLvv/9e0tXXO95++21JUrNmzfT222/bt2/FxIkTdfjwYQ0dOlQDBgyQdHVGx44dO9SxY0e9/PLLeuyxx7Rlyxb16dMnw8N1Zi5duqSnn35aNWrU0JgxY1S5cmVNnTpVmzZtuumx6enp6t+/v/z8/DR69GjdddddWrBggZYvX27vY7VaNWTIEK1du1adO3fWyJEjFR0drTFjxjj/B/EvL7/8smbOnKlatWpp7NixatSokebMmaORI0dmedzy5cs1duxYDRgwwF5LTu+Z5557TomJiXr++efVvn17rVq1SrNmzbLv//vvvzVo0CBZLBaNGDFCY8aMUZs2bbR9+/abXteOHTsUGhqawz8NRx9++KHGjBmjChUq6MUXX1SfPn3s1xgfH5/j8fbt2ydJCgsLc2gvWbKkSpUqlWFmh7e3t8qXL5+t6wUAFHy8cgIAuK2GDBmiL7/8UvPmzdPLL7+ca+PWqVNHr732mqSra0i0adNGb731lp5//nkNHDhQkvTggw+qRYsW+vzzz9WoUSOH4y9duqR169bZf6pcq1YtPffcc1qxYoX69Okjm82mCRMmqHHjxpo/f75MJpMk6bHHHlPHjh01Y8aMDLM/atSooWnTpt209rlz5yomJkbLli1Tw4YNJUndunXTww8/rMmTJ6tt27YKDg5WcHCwRo8erYoVK2b56khO+Pr66pNPPnFYU+Gee+7RAw884NCvdevW6tGjh7799ls98sgjWY55/vx5TZkyxd6va9euatOmjT7//HP7LJAbSUlJUfv27TV06FBJUs+ePdW5c2etXLnSPstlw4YN2rFjh8aNG6cnn3zS3q9fv345ufRM/fXXX1q9erW6deumN954Q5L0xBNPqHjx4lqwYIG2bNmiu+++O8Nxixcv1ptvvqkRI0bomWeekSSn7pmaNWvqzTfftG9fvHhRK1eu1AsvvCDp6uyM1NRUzZs3T8WLF8/2daWlpenEiRO3tPZEVFSU3n//fT333HMaPHiwvf2+++5T586d9emnnzq0Z0d0dLSkq+tjXC8oKEjnz5/P0B4cHKxDhw7lsHoAQEHEDA0AwG0VHByshx9+WCtWrMj0YcVZXbt2tf/e1dVVtWvXls1mc2j38fFRpUqVdPLkyQzHP/LIIw5T5B944AEFBQXZZxXs379fx44d00MPPaS4uDhduHBBFy5c0JUrV9SkSRP98ccfslqtDmM+9thj2ap906ZNqlOnjj3MkK6uIdCjRw9FRUXl6cNb9+7dHcIMSfL09LT/PjU1VXFxcSpfvrx8fHzsP1HPStGiRR0CF7PZrLCwsEz/3DPTs2dPh+0GDRo4vO7yyy+/yN3dXd27d7e3ubi46IknnsjW+Fm59vd9fTjy1FNPOez/t3nz5mnSpEn6z3/+Yw8zpNy5Zxo2bKiLFy8qISFBkuzrp2zcuDHDsVm5dOmSbDbbTddfycr3338vq9Wq9u3b26/lwoULCgwMVIUKFZz6fO+1GVBmsznDPg8PD4cZUtf4+PgoLi4u5xcAAChwmKEBALjtnnnmGa1Zs0Zz587NtVkaZcqUcdj29vaWh4dHhp9ie3t76+LFixmOr1ChgsO2yWRShQoV7J/4PHbsmCRl+VrD5cuX5evra9/O7iKTp0+fVt26dTO0V65c2b6/evXq2RorpzKrMTk5WXPmzNGqVat07tw52Ww2+77Lly/fdMxSpUrZZyNc4+vrqwMHDtz02Mz+znx9fXXp0iX79unTpxUUFKQiRYo49LvVr7ZIV2chuLi4ZBgrKChIPj4+GT75+vvvv9tfVXr66acd9jlzz1x/H18LIC5duiQvLy916NBB//vf//Tyyy9r2rRpatKkie6991498MADcnG5+c+p/v13mVPHjh2TzWbTfffdl+l+Z75Ycy08y2x9kpSUFIdw7RqbzZbh/gIAFE4EGgCA2+7fszSuvQ7ybzd6WLl+Ych/y+xh7vqZB9c481B37ZjRo0erZs2amfa5/gsh+fEVj5zKrMbXX39dq1at0pNPPql69erJ29tbJpPJvk7Jzdzozz07buXY3JTdB+Zq1aopPj5eX375pXr06OHw5Q1n7pkbhRLXxvL09NSyZcu0detW/fTTT/rll1+0bt06LV++XAsWLLjhn5+vr69MJpNT61xcY7VaZTKZNG/evEzP48xXfK69ahIdHa3SpUs77IuOjladOnUyHBMfH+/wiV0AQOFFoAEAyBdDhgzRmjVrMv3iybWfWF//8HX69Ok8q+f48eMO2zabTcePH7d/SeTag6qXl5f9Swu5pUyZMjp69GiG9iNHjtj3307X1sl48cUX7W0pKSnZmp1xO5QpU0Zbt25VUlKSwyyNEydO3PLYZcuWldVq1fHjxx0+FxoTE6P4+HiVLVvWob+/v79mzpypxx9/XH379tWnn35q/yRxXt0zLi4uatKkiZo0aaKxY8fqo48+0rvvvqutW7fe8Dxubm4qX758hi/V5ET58uVls9lUrlw5VapUyelx/u1a0BMZGekQXpw7d05nz551eK3omlOnTqlGjRq5cn4AgLGxhgYAIF+UL19eDz/8sJYvX25fGPAaLy8v+fv7688//3Ro//TTT/Osni+++MK+ToEkrV+/XtHR0WrZsqUkqXbt2ipfvrwWLFigxMTEDMdfuHDB6XO3atVKu3fv1o4dO+xtV65c0YoVK1S2bFlVrVrV6bGdkdlP35csWZLlDJnbqXnz5kpNTdWKFSvsbVarVcuWLbvlsa8tWrpo0SKH9oULFzrs/7dSpUpp4cKFSklJ0VNPPWVf3yEv7pnMXpe6Fgrc7LOy9erV0549e3J8zmvuu+8+ubq6atasWRlm6thsNqfWtahWrZoqV66sFStWONxf//3vf2UymTIsTnv58mWdOHFC4eHhzl0EAKBAYYYGACDfDB48WF9++aWOHj2qatWqOezr1q2b5s6dq5deekm1a9fWn3/+mekshtzi6+urxx9/XF26dFFsbKwWLVqkChUq2H9C7OLiojfeeEMDBgzQgw8+qC5duqhkyZI6d+6ctm7dKi8vL3300UdOnXvgwIFau3at/ZOxvr6++uKLL3Tq1Cm9//772VobITfdc889+vLLL+Xl5aWqVatq586d2rx5s/z8/G5rHTfSrl071alTR1OmTNGJEydUuXJl/fDDD/Z1Nm5lfYUaNWqoc+fOWr58ueLj49WoUSNFRkZq9erVateuXaZfOJGursHy8ccfq0+fPurfv78WL14sLy+vXL9nZs+erT///FOtWrVS2bJlFRsbq08//VSlSpVSgwYNsjy2bdu29v+9XT/D4oMPPpAk+wK0X375pbZt2yZJ9oVOy5cvr+eee07Tpk1TVFSU2rVrp2LFiunUqVPasGGDunfvrv79+0u6GjwsWbJEkuyfWF22bJm8vb3l4+OjXr162c89evRoDRkyRE899ZQ6duyogwcPatmyZerWrZvDLBlJ2rx5s2w22y19rQUAUHAQaAAA8k2FChX08MMPa/Xq1Rn2DR06VBcuXNC3336rb775Ri1bttT8+fPVpEmTPKll8ODBOnDggObOnavExEQ1adJEr776qsMrDY0bN9by5cv1wQcfaOnSpbpy5YqCgoJUp04d9ejRw+lzBwYG6rPPPtM777yjpUuXKiUlRSEhIfroo490zz335MLV5cxLL70kFxcXffXVV0pJSVH9+vW1cOHCDIte5hdXV1fNmTNHkyZN0urVq+Xi4qJ7771XQ4cOVc+ePW957ZI33nhD5cqV0+rVq7VhwwYFBgZq0KBBGjZsWJbHhYSEaN68eerbt68GDx6s+fPn5/o906ZNG0VFRenzzz9XXFyc/P39ddddd2n48OHy9vbO8tjWrVvL399f33zzjcPXWCTpvffec9j+/PPP7b//d9+BAweqYsWK+uSTTzR79mxJV2eoNGvWTG3atLH3u3TpUoYxr32itmzZsg6BRuvWrTVr1izNmjVLr7/+uooXL65BgwbZP937b+vXr1eDBg1yZQFYAIDxmWy3stw1AADAHWLDhg0aOnSoPv3005vOViisZs+erVWrVum77767YxZgza7o6Gi1bdtW06dPV7t27fK7HADAHYA1NAAAgOEkJyc7bKenp2vJkiXy8vJSaGhoPlV15+vbt6+uXLmitWvX5ncpObZo0SJVr16dMAMAYMcMDQAAYDgvvfSSkpOTFR4eLovFou+++047duzQ888/r0GDBuV3eQAA4DYg0AAAAIbz1VdfaeHChTp+/LhSUlJUoUIF9ezZ02FtBgAAULARaAAAAAAAAMNhDQ0AAAAAAGA4BBoAAAAAAMBwCDQAAAAAAIDhEGgAAAAAAADDIdAAAAAAAACGQ6ABAAAAAAAMh0ADAAAAAAAYDoEGAAAAAAAwnP8DhTHgMcyozxIAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Define your paths\n",
        "# The folder you want to upload (e.g., your checkpoint)\n",
        "source_folder = \"./results_pretrain/checkpoint-765\"\n",
        "\n",
        "# Where you want it in Drive (this creates a 'Models' folder in your Drive root)\n",
        "destination_folder = PROJECT_ROOT / \"BulkRNABert_Models\""
      ],
      "metadata": {
        "id": "xq9sVaBC1PWV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "# Create destination directory\n",
        "os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "print(f\"Copying files to {destination_folder}...\")\n",
        "\n",
        "# Use shell command for recursive copy (often faster than python shutil for massive folders)\n",
        "# -r = recursive, -v = verbose (shows progress)\n",
        "!cp -r -v \"$source_folder\" \"$destination_folder\"\n",
        "\n",
        "print(\" Copy complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bshTjbO1PTg",
        "outputId": "edb347f7-691c-40f9-a1da-0b2caf0ed21b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying files to /content/drive/MyDrive/bdh_challenge_2025_data/BulkRNABert_Models...\n",
            "cp: cannot stat './results_pretrain/checkpoint-765': No such file or directory\n",
            " Copy complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the same preprocessor you used before (same global_max, bins)\n",
        "preprocessor = RNAPreprocessor(num_bins=CONFIG['n_bins'])\n",
        "tokenized_data = preprocessor.fit_transform(expr_aligned.values)  # numpy array\n",
        "\n",
        "# Dataset for encoding (no survival here)\n",
        "full_dataset = BulkRNADataset(tokenized_data)\n"
      ],
      "metadata": {
        "id": "erZNPZge1PQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "encoder = bert_encoder.to(device)\n",
        "encoder.eval()\n",
        "\n",
        "loader = DataLoader(full_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "all_embeddings = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in loader:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        outputs = encoder(input_ids=input_ids)\n",
        "\n",
        "        # Option 1: CLS embedding (first token)\n",
        "        cls_emb = outputs.last_hidden_state[:, 0, :]   # (batch, 256)\n",
        "\n",
        "        # Option 2 (alternative): mean-pool across genes\n",
        "        # cls_emb = outputs.last_hidden_state.mean(dim=1)\n",
        "\n",
        "        all_embeddings.append(cls_emb.cpu().numpy())\n",
        "\n",
        "X_embed = np.vstack(all_embeddings)  # (n_samples, 256)\n",
        "emb_df = pd.DataFrame(X_embed, index=expr_aligned.index)\n"
      ],
      "metadata": {
        "id": "KLftRpJWcZMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb_df.to_parquet(PROCESSED_DIR / \"tcga_bulkrnabert_embeddings.parquet\")\n"
      ],
      "metadata": {
        "id": "xevhVn3F1PNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a39j4G0K1PIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JWbqPshP1O_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hc-0HbyD1OwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Md5Z6htomgto"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}